十、Advice for Applying Machine Learning
===



## Evaluating a Learning Algorithm


## 10.1 Deciding What to Try Next(决定下一步做什么)

到目前为止 我们已经介绍了许多不同的学习算法 

如果你一直跟着这些视频的进度学习 你会发现自己已经不知不觉地 成为一个了解许多先进机器学习技术的专家了 然而 在懂机器学习的人当中 依然存在着很大的差距 一部分人确实掌握了 怎样高效有力地 运用这些学习算法 而另一些人 他们可能对我马上要讲的东西 就不是那么熟悉了 他们可能没有完全理解 怎样运用这些算法 因此总是 把时间浪费在 毫无意义的尝试上 

我想做的是 确保你在设计 机器学习的系统时 你能够明白怎样选择 一条最合适 最正确的道路 因此 在这节视频 和之后的几段视频中 我将向你介绍一些实用的 建议和指导 帮助你明白怎样进行选择 具体来讲 我将重点关注的问题是 假如你在开发 一个机器学习系统 或者想试着改进 一个机器学习系统的性能 你应如何决定 接下来应该 

选择哪条道路？ 

为了解释这一问题 我想仍然使用 预测房价的学习例子 假如你已经完成了正则化线性回归 也就是最小化代价函数J的值 假如 在你得到你的学习参数以后 如果你要将你的假设函数 放到一组新的房屋样本上进行测试 假如说你发现在预测房价时 产生了巨大的误差 

现在你的问题是 要想改进这个算法 接下来应该怎么办？ 

实际上你可以想出 很多种方法来改进 这个算法的性能 

![10.1.1](http://a1.qpic.cn/psb?/V12umJF70r2BEK/98MZFlO6SfD6n5XIIl7SK7kw1.RK5MyhoPcvnGZrpy8!/b/dAwBAAAAAAAA&ek=1&kp=1&pt=0&bo=LAO7AQAAAAARF7U!&tl=3&vuin=904260897&tm=1535792400&sce=60-2-2&rf=viewer_4)

- (Get more training examples)其中一种办法是 使用更多的训练样本 具体来讲 也许你能想到 通过电话调查 或上门调查 来获取更多的 不同的房屋出售数据 

遗憾的是 我看到好多人花费了好多时间 想收集更多的训练样本 他们总认为 噢 要是我有 两倍甚至十倍数量的训练数据 那就一定会解决问题的 是吧？ 但有时候 获得更多的训练数据 实际上并没有作用 在接下来的几段视频中 我们将解释原因 我们也将知道 怎样避免把过多的时间 浪费在收集更多的训练数据上 这实际上是于事无补的 

- (Try smaller sets of feartures)另一个方法 你也许能想到的 是尝试选用更少的特征集 因此如果你有一系列特征 比如x1 x2 x3等等 也许有很多特征 也许你可以花一点时间 从这些特征中 仔细挑选一小部分来防止过拟合 

- (Try getting additional features)或者也许你需要用更多的特征 也许目前的特征集 对你来讲并不是很有帮助 你希望从获取更多特征的角度 来收集更多的数据 

同样地 你可以把这个问题 扩展为一个很大的项目 比如使用电话调查 来获得 更多有关 或者再进行土地测量 来获得更多有关 这块土地的信息等等 因此这是一个复杂的问题 同样的道理 我们非常希望 在花费大量时间完成这些工作之前 我们就能知道其效果如何 

- (Try adding polynomial features)我们也可以尝试 增加多项式特征的方法 比如x1的平方 x2的平方 x1 x2的乘积 我们可以花很多时间 来考虑这一方法 
  
- (Try decreasing or increasing $\lambda$)我们也可以考虑其他方法 减小或增大正则化参数lambda的值 

我们列出的这个单子 上面的很多方法 都可以扩展开来 扩展成一个六个月或更长时间的项目 

遗憾的是 大多数人用来选择这些方法的标准 是凭感觉的 也就是说 大多数人的选择方法是 随便从这些方法中选择一种 比如他们会说 “噢 我们来多找点数据吧” 然后花上六个月的时间 收集了一大堆数据 然后也许另一个人说 “好吧 让我们来从这些房子的数据中多找点特征吧” 我很遗憾不止一次地看到 很多人花了 不夸张地说 至少六个月时间 来完成他们随便选择的一种方法 而在六个月或者更长时间后 他们很遗憾地发现 自己选择的方法效果并不好

幸运的是 有一系列简单的方法 能让你事半功倍 排除掉单子上的 至少一半的方法 留下那些确实有前途的方法 同时也有一种很简单的方法 只要你使用 就能很轻松地排除掉很多选择 

从而为你节省 大量不必要花费的时间 

在接下来的两段视频中 我首先介绍 怎样评估机器学习算法的性能 

然后在之后的几段视频中 我将开始 讨论这些方法 

它们也被称为"机器学习诊断法"(Machine learning diagnostic) 

“诊断法”的意思是 这是一种测试法 你通过执行这种测试 能够深入了解 某种算法到底哪里出了问题 这通常也能够告诉你 要想改进一种算法的效果 什么样的尝试 才是有意义的 

在这一系列的视频中我们将介绍具体的诊断法 但我要提前说明一点的是 这些诊断法的执行和实现 是需要花些时间的 有时候 确实需要花很多时间 来理解和实现 但这样做的确是 更有效率地利用好你的时间 因为这些方法 让你在开发学习算法时 节省了几个月的时间 早点从不必要的尝试中解脱出来 早日脱离苦海 

因此 在接下来几节课中 我将先来介绍 如何评价你的学习算法 在此之后 我将介绍一些诊断法 希望能让你更清楚 在接下来的尝试中 如何选择更有意义的方法 最终达到改进机器学习系统性能的目的 



​具体来讲，我将重点关注的问题是假如你在开发一个机器学习系统，或者想试着改进一个机器学习系统的性能，你应如何决定接下来应该选择哪条道路？为了解释这一问题，我想仍然使用预测房价的学习例子，假如你已经完成了正则化线性回归，也就是最小化代价函数$J$的值，假如，在你得到你的学习参数以后，如果你要将你的假设函数放到一组新的房屋样本上进行测试，假如说你发现在预测房价时产生了巨大的误差，现在你的问题是要想改进这个算法，接下来应该怎么办？

​	实际上你可以想出很多种方法来改进这个算法的性能，其中一种办法是使用更多的训练样本。但有时候获得更多的训练数据实际上并没有作用。在接下来的几段视频中，我们将解释原因。

​	我们也将知道怎样避免把过多的时间浪费在收集更多的训练数据上。

另一个方法，你也许能想到的是尝试选用更少的特征集。因此如果你有一系列特征比如$x_1,x_2,x_3$等等。也许有很多特征，也许你可以花一点时间从这些特征中仔细挑选一小部分来防止过拟合。或者也许你需要用更多的特征，也许目前的特征集，对你来讲并不是很有帮助。

同样的道理，我们非常希望在花费大量时间完成这些工作之前，我们就能知道其效果如何。

我们也可以尝试增加多项式特征的方法，比如$x_1$的平方，$x_2$的平方，$x_1,x_2$的乘积，我们可以花很多时间来考虑这一方法，我们也可以考虑其他方法减小或增大正则化参数$\lambda$的值。

我们需要用一个线性回归模型来预测房价，当我们运用训练好了的模型来预测未知数据的时候发现有较大的误差，我们下一步可以做什么？

获得更多的训练实例——通常是有效的，但代价较大，下面的方法也可能有效，可考虑先采用下面的几种方法。

尝试减少特征的数量

尝试获得更多的特征

尝试增加多项式特征

尝试减少正则化程度$\lambda$

尝试增加正则化程度$\lambda$

​ 我们不应该随机选择上面的某种方法来改进我们的算法，而是运用一些机器学习诊断法来帮助我们知道上面哪些方法对我们的算法是有效的。

​	在接下来的两段视频中，我首先介绍怎样评估机器学习算法的性能，然后在之后的几段视频中，我将开始讨论这些方法，它们也被称为"机器学习诊断法"。“诊断法”的意思是：这是一种测试法，你通过执行这种测试，能够深入了解某种算法到底是否有用。这通常也能够告诉你，要想改进一种算法的效果，什么样的尝试，才是有意义的。在这一系列的视频中我们将介绍具体的诊断法，但我要提前说明一点的是，这些诊断法的执行和实现，是需要花些时间的，有时候确实需要花很多时间来理解和实现，但这样做的确是把时间用在了刀刃上，因为这些方法让你在开发学习算法时，节省了几个月的时间，因此，在接下来几节课中，我将先来介绍如何评价你的学习算法。在此之后，我将介绍一些诊断法，希望能让你更清楚。在接下来的尝试中，如何选择更有意义的方法。





## 10.2 Evaluating a Hypothesis(评估假设)

在之后的课程中 我们将以此为基础来 讨论如何避免 过拟合和欠拟合的问题 

当我们确定学习算法的参数的时候 我们考虑的是选择参量来使训练误差最小化 

有人认为 得到一个非常小的训练误差 一定是一件好事 但我们已经知道 仅仅是因为这个假设具有很小的训练误差 并不能说明它就一定是一个好的假设函数 而且我们也学习了过拟合假设函数的例子 所以这推广到新的训练集上是不适用的 

那么 你该如何判断一个假设函数是过拟合的呢

对于这个简单的例子 我们可以 对假设函数 h(x) 进行画图 然后观察图形趋势 

![10.2.1](http://m.qpic.cn/psb?/V12umJF70r2BEK/pz.y6WdXRtTj*fwkrso1hCqH7JAxUXnugX6LqXlbxxQ!/b/dIwBAAAAAAAA&bo=PAO.AQAAAAARF6A!&rf=viewer_4)

但对于特征变量不止一个的这种一般情况 还有像有很多特征变量的问题 想要通过画出假设函数来进行观察 就会变得很难甚至是不可能实现 因此 我们需要另一种方法来评估我们的假设函数 如下给出了一种评估假设函数的标准方法 假设我们有这样一组数据组 

![10.2.2](http://m.qpic.cn/psb?/V12umJF70r2BEK/tQDFBwm9XQcSVaq..4VdTj5vSZ7qvFRd0eXL*D8fZng!/b/dAsAAAAAAAAA&bo=MwO5AQAAAAARF6g!&rf=viewer_4)

在这里我只展示出10组训练样本 当然我们通常可以有 成百上千组训练样本。

为了确保我们可以评估我们的假设函数，我们要做的是，将这些数据分成两部分： 

第一部分将成为我们的训练集 

而第二部分将成为我们的测试集

将所有数据分成训练集和测试集 其中一种典型的分割方法是 按照7:3的比例 将70%的数据作为训练集 30%的数据作为测试集 因此 现在如果我们有了一些数据 我们只用其中的70% 作为我们的训练集 

这里的m依然表示训练样本的总数 

而剩下的那部分数据 将被用作测试集 在这里 我使用$m_test$ 来表示测试样本的总数 因此 这里的下标test将表示 这些样本是来自测试集 

因此$x^{(1)}_{test} \ y^{(1)}_{test}$将成为我的 第一组测试样本  最后再提醒一点 在这里我是选择了前70%的数据作为训练集 后30%的数据作为测试集 但如果这组数据有某种规律或顺序的话 那么最好是 随机选择70%作为训练集 剩下的30%作为测试集 

当然如果你的数据已经随机分布了 那你可以选择前70%和后30% 但如果你的数据不是随机排列的,最好还是打乱顺序,或者使用一种随机的顺序来构建你的数据 然后再取出前70%作为训练集 后30%作为测试集 

接下来 这里展示了一种典型的方法 你可以按照这些步骤训练和测试你的学习算法 比如

$$线性回归算法$$

首先 你需要对训练集进行学习得到参数$θ$ 具体来讲就是最小化训练误差$J(θ)$ 这里的$J(θ)$是使用那70%数据 来定义得到的

接下来 你要计算出测试误差 我将用$J_{test}$来表示测试误差 

那么你要做的就是 取出你之前从训练集中学习得到的参数θ放在这里 来计算你的测试误差 可以写成如下的形式 

$$J_{test}(\theta)= \frac{1}{2m_{test}} \sum^{m_{test}}_{i=1}( h_\theta(x^{(i)}_{test})-y^{(i)}_{test} )^2 $$

这实际上是测试集 平方误差的 平均值

我们使用包含参数θ的假设函数对每一个测试样本进行测试,我们使用包含参数$\theta$的假设函数对每一个测试样本进行测试，然后在$m_test$个测试样本上，计算出假设函数的平方误差 

当然 这是当我们使用线性回归 和平方误差标准时 测试误差的定义 

那么如果是考虑分类问题 比如说

$$逻辑回归算法$$ 

训练和测试逻辑回归的步骤 与之前所说的非常类似 

首先我们要从训练数据 也就是所有数据的70%中 学习得到参数θ 

然后用如下的方式计算测试误差,目标函数和我们平常 做逻辑回归的一样 唯一的区别是 
现在我们使用的是$m_{test}$个测试样本 这里的测试误差$J_test(θ)$的定义非常合理 有时这是另一种形式的测试集 可能更易于理解，叫做错误分类(misclassification error),也被称为0/1分类错误,0/1表示了你预测的分类是正确或错误的情况

比如说 可以这样定义一次预测的误差 关于假设$h(x)$ 和标签$y$的误差 那么这个误差等于1的情况是

当你的假设函数h(x)的值大于等于0.5 并且y的值等于0 或者当h(x)小于0.5 并且y的值等于1 



$$
err(h_\theta(x),y) = \begin{cases}
1, & \text{if } h_\theta(x) >= 0.5 && y=0 ; or \text{if} h_\theta(x) <= 0.5 && y=1 \\
0, & \text{otherwise } .
\end{cases}$$

因此 这两种情况都表明 你的假设对样本进行了误判 

这里定义阈值为0.5 那么也就是说 假设结果更趋向于1 但实际是0 或者说假设预测更趋向于0 但实际的标签却是1 

否则 我们将误差值定义为0 此时你的假设值能够正确对样本y进行分类 

![10.2.3](http://m.qpic.cn/psb?/V12umJF70r2BEK/g*g8yQRwXX82xXuvRYzeZ8hPKDkC7ENkqtVbTfPtFqY!/b/dAkBAAAAAAAA&bo=RwO7AQAAAAARF94!&rf=viewer_4)

然后 我们就能应用错分率误差 来定义测试误差 也就是

$$Test\ error = \frac{1}{m_{test}}\sum^{m_{test}}_{i=1}err(  h_\theta{(x^{(i)}_{test})},y_{test}^{(i)})$$

这样我就写出了我的定义方式 这实际上就是我的假设函数误标记的 那部分测试集中的样本 

这也就是使用 **0/1错分率或误分类率** 的准则来定义的测试误差 


以上我们介绍了一套标准技术 来评价一个已经学习过的假设 在下一段视频中我们要应用这些方法 来帮助我们进行诸如特征选择一类的问题 比如多项式次数的选择 或者正则化参数的选择


## 10.3 Model Selection and Train/Validation/Test Sets(模型选择与训练/验证/测试集)

假如你想要确定对于某组数据 最合适的多项式次数是几次 怎样选用正确的特征来构造学习算法 或者假如你需要正确选择 学习算法中的正则化参数λ 你应该怎样做呢？ 这些问题我们称之为**模型选择问题**

在我们对于这一问题的讨论中 我们还将提到 如何将数据分为三组 也就是**训练集**、**验证集**和**测试集** 而不仅仅是前面提到的两组数据 

我们已经多次接触到过拟合现象 在过拟合的情况中  学习算法在适用于训练集时表现非常完美  但这并不代表此时的假设也很完美 更一般地说 这也是为什么训练集误差 通常不能正确预测出该假设是否能很好地拟合新样本的原因 

具体来讲 如果你把这些参数集 比如$θ_0$ $θ_1$ $θ_2$等等 调整到非常拟合你的训练集 那么结果就是 你的假设会在训练集上表现地很好  但这并不能确定 当你的假设推广到训练集之外的新的样本上时  预测的结果是怎样的 

而更为普遍的规律是 只要你的参数非常拟合某个数据组 比如说 非常拟合训练集 当然也可以是其他数据集 那么你的假设对于相同数据组的预测误差 比如说训练误差 是不能够用来推广到一般情况的 

或者说 是不能作为实际的泛化误差的 也就是说 不能说明你的假设对于新样本的效果 

下面我们来考虑模型选择问题 

![10.3.1](http://a2.qpic.cn/psb?/V12umJF70r2BEK/6LtNSCff18x1by*JDVyzgtWmFxjTkC2uhbIcpQ5FcAI!/b/dA0BAAAAAAAA&ek=1&kp=1&pt=0&bo=QwPiAQAAAAARF4M!&tl=3&vuin=904260897&tm=1535889600&sce=60-2-2&rf=viewer_4)

假如说你现在要选择能最好地拟合你数据的多项式次数 换句话说 你应该选择一次函数 二次函数 还是三次函数呢 等等一直到十次函数 
所以似乎应该有这样一个参数 这里我用 $d$ 来表示 $d$表示的就是你应该选择的多项式次数

所以 似乎除了你要确定的参数θ之外 你还要考虑确定一个参数 

你同样需要用你的数据组来确定这个多项式的次数$d$ 第一个选择是 $d=1$ 也就表示线性(一次)方程 我们也可以选择d=2或者3 等等一直到d=10 

因此 我们想确定这个多出来的参数d最适当的取值 

具体地说 比如你想要选择一个模型  那就从这10个模型中 选择一个最适当的多项式次数 并且用这个模型进行估计 预测你的假设能否很好地推广到新的样本上

那么你可以这样做 

你可以先选择第一个模型 然后求训练误差的最小值 

这样你就会得到 一个参数向量θ 然后你再选择第二个模型 二次函数模型  

进行同样的过程 这样你会得到另一个参数向量 θ 为了区别这些不同的 参数向量θ 

我想用上标(1) 上标(2)来表示 

这里的上标(1)表示的是 在调整第一个模型 使其拟合训练数据时得到的参数θ 

同样地 θ上标(2)表示的是 二次函数在和训练数据拟合的过程中得到的参数  
以此类推 

在拟合三次函数模型时我又得到一个参数θ(3) 等等 直到θ(10)  

接下来我们要做的是 对所有这些模型 求出测试集误差 

因此 我可以算出 $J_{test}(θ^{(1)}) \   J_{test}(θ^{(2)}) \  J_{test}(θ^{(3)})$ 以此类推 也就是对于每一个模型对应的假设 都计算出其作用于测试集的表现如何 接下来为了确定选择哪一个模型最好 我要做的是 

看看这些模型中 哪一个对应的测试集误差最小 

假设对于这一个例子 我们最终选择了五次多项式模型 

目前看来还比较合理 那么现在 我确定了我的模型 我得到了我的假设 也就是这个五次函数模型 

现在我想知道 这个模型能不能很好地推广到新样本 

我们可以观察这个五次多项式假设模型  对测试集的拟合情况 但这里有一个问题是 这样做仍然不能公平地说明 我的假设推广到一般时的效果 

其原因在于 我们刚才是使用的测试集 跟假设拟合 来得到的 多项式次数$d$ 这个参数 这也就是说 我们选择了一个 能够**最好地拟合测试集**的 参数$d$的值 

因此 我们的参数向量$θ^{(5)}$ 在**拟合测试集**时的结果  很可能导致一个比实际泛化误差更完美的预测结果 

因为我是找了一个最能拟合测试集的参数$d$ 因此我再用测试集 来评价我的假设就显得不公平了 

因为我已经选了一个能够最拟合测试集的参数 我选择的多项式次数$d$ 本身就是按照最拟合测试集来选择的 

因此我的假设 很可能很好地拟合测试集 而且这种拟合的效果很可能会比对那些没见过的新样本拟合得更好 而我们其实是更关心对新样本的拟合效果的 

所以 再回过头来说 在前面的幻灯片中 我们看到 如果我们 用训练集来拟合参数 $θ_0\ θ_1$ 等等参数时 那么 拟合后的模型 在作用于训练集上的效果 是不能预测出 我们将这个假设推广到新样本上时效果如何的 

这是因为这些参数能够很好地拟合训练集 因此它们很有可能 在对训练集的预测中表现地很好 但对其他的新样本来说 就不一定那么好了 

具体来讲 我们做的实际上是用测试集来拟合参数d 通过用测试集来拟合这个参数 同样也意味着 这并不能较为公平地预测出 假设函数的在遇到新样本时的表现 

为了解决这一问题 在模型选择中 如果我们想要评价某个假设 我们通常采用以下的方法: 

给定某个数据集 和刚才将数据分为 训练和测试集不同的是 我们要将其分为三段 第一部分还是叫训练集 第二部分我把它叫做交叉验证集（cross validation set） 

Cross validation 

我用CV来简写“交叉验证” 有时候也直接叫验证集 最后一部分依然和以前一样是测试集 同时 一种典型的分割比例是 6:2:2,这个比例可以稍微调整 但这种分法是最典型的 

![10.3.2](http://m.qpic.cn/psb?/V12umJF70r2BEK/9CBuFVT0rlMTvm2nrNMg86BJd68EGspknNPfrUPBGSM!/b/dNoAAAAAAAAA&bo=MAPFAQAAAAARF9c!&rf=viewer_4)

所以现在我们的训练集就只占总数据的60%了 然后交叉验证集 或者说验证集 将拥有一部分样本 

我把它的数量用m下标CV来表示 这是交叉验证集样本的数量 

按照之前我们的符号表示习惯 我将用$(x^{(i)}_{CV}, y^{(i)}_{CV})$ 来表示第$i$个交叉验证样本 

最后 我们还是有这样一些测试集样本 用$m_{test}$来表示测试样本的总数 

好的 现在我们就定义了训练集、交叉验证集 以及测试集 

我们随之也可以定义训练误差 交叉验证误差 和测试误差 

因此这便是我定义的训练误差 我用$J_{train}(\theta)$来表示 这跟我们之前定义的 $J(θ)$ 没有任何区别 也就是对训练集数据进行预测得到的误差 然后$J_{CV}(\theta)$定义为交叉验证集误差 

![10.3.3](http://m.qpic.cn/psb?/V12umJF70r2BEK/S7liH7n42CKzkhwVFubpO5IYrI7ySmxjN6N8gubpCDQ!/b/dPQAAAAAAAAA&bo=MwO9AQAAAAARF6w!&rf=viewer_4)

这也不难想象 跟训练误差类似的定义 只不过是在交叉验证集上预测得到的误差 

然后这是测试集 跟前面一样 

那么我们的模型选择问题是这样的 和之前使用测试集来选择模型不同 我们现在要使用验证集 或者说交叉验证集来选择模型 

具体来讲 首先我们用第一个假设函数 也就是第一个模型 然后求代价函数的最小值 然后我们会得到这个线性模型对应的参数向量$θ^{(1)}$ 和之前一样 我们还是用上标(1)来表示 这个参数是对应于线性模型的 对二次函数 我们也做同样的事情 这样可以得到$θ^{(2)}$ 然后是$θ^{(3)}$ 等等以此类推 一直到10次多项式 

然后我要做的是 跟之前用测试集来预测这些假设不同 我要在交叉验证集中测试这些假设的表现 我要测出$J_{cv}$来看看 这些假设在交叉验证集中表现如何 

然后我要选择的是交叉验证集误差最小的那个假设作为我们的模型

因此 对于这个例子 假如是 四次函数的模型有最小的交叉验证误差 因此 我们就选择这个四次多项式模型 

最后 这样做的意义是 参数$d$ 别忘了参数$d$ 是多项式的次数 $d=2$ $d=3$ 一直到$d=10$ 

![10.3.4](http://m.qpic.cn/psb?/V12umJF70r2BEK/mzRQCpo8kIKadOfUcOG8PBuewXXbK1NLETVDK3Q3IsE!/b/dN0AAAAAAAAA&bo=YAPFAQAAAAARF4c!&rf=viewer_4)

我们刚才做的是拟合出最好的系数$d$等于4 并且我们是通过交叉验证集来完成的 

因此 这样一来这个参数$d$ 即这个多项式的次数 就没有跟测试集进行拟合 这样我们就回避了测试集的嫌疑 我们可以光明正大地使用测试集 来估计所选模型的泛化误差了 

好的 这就是模型选择了 以及你应该怎样 将数据分成训练集、验证集和测试集 以及使用你的交叉验证集数据来选择模型 

最后用测试集来评价模型的表现 

最后我还想提醒的一点是 在如今的机器学习应用中 确实也有很多人是像我之前介绍的那样做的 我说过这并不是一个好的方法 
也就是用测试集来选择模型 然后用同样的测试集来 评价模型的表现 报告测试误差 

看起来好像还能得到比较不错的泛化误差 这的确是一种做法 但不幸的是 现在还有很多人这样做 如果你有很多很多测试集的话 这也许还能行得通 但大多数的机器学习开发人员 还是不会选择这样做 因为最佳做法还是把数据分成训练集、验证集、测试集  






## Bias vs. Variance



## 10.4 Diagnosing Bias vs. Variance(诊断偏差与方差)
当你运行一个学习算法时 如果这个算法的表现不理想 那么多半是出现 两种情况:

1、偏差比较大   
2、方差比较大   
换句话说 出现的情况要么是**欠拟合** 要么是**过拟合**问题 

那么这两种情况 哪个和偏差有关 哪个和方差有关 或者是不是和两个都有关 

搞清楚这一点非常重要 因为能判断出现的情况 是这两种情况中的哪一种 其实是一个很有效的指示器 指引着可以改进算法的 最有效的方法和途径 

在这段视频中 我想更深入地探讨一下 有关偏差和方差的问题 希望你能对它们有一个更深入的理解 并且也能弄清楚怎样评价一个学习算法 能够判断一个算法是偏差还是方差有问题 因为这个问题对于弄清 如何改进学习算法的效果非常重要 

![10.4.1]()

如果你用两个很简单的假设来拟合数据 比如说用一条直线 那么不足以拟合这组数据(欠拟合) 

而如果你用两个很复杂的假设来拟合时 那么对训练集来说 则会拟合得很好 但又过于完美(过拟合) 

而像这样的 中等复杂度的假设 比如某种二次多项式的假设 次数既不高也不低 这种假设对数据拟合得刚刚好 此时对应的的泛化误差 也是三种情况中最小的 

现在我们已经掌握了 训练集 验证集和测试集的概念 我们就能更好地理解 偏差和方差的问题 

具体来说 我们沿用之前所使用的 训练集误差和验证集误差的定义 也就是平方误差 即对训练集数据进行预测 或对验证集数据进行预测 所产生的平均平方误差 

下面我们来画出如下这个示意图 横坐标上表示的是 多项式的次数 因此横坐标越往右的位置 表示多项式的次数越大 

![10.4.2]()

那么我们来画这幅图对应的情况 d可能等于1的情况 是用很简单的函数 来进行拟合 而在右边的这个图中 水平横坐标表示 有更多更大的d值 表示更高次数的多项式 因此这些位置对应着使用 更复杂的函数来拟合你的训练集时所需要的d值 

让我们来把训练集误差 和交叉验证集误差画在这个坐标中 我们先来画训练集误差 随着我们增大多项式的次数 我们将对训练集拟合得越来越好 所以如果d等于1时 对应着一个比较大的训练误差 而如果我们的多项式次数很高时 我们的训练误差就会很小 甚至可能等于0 因为可能非常拟合训练集 所以 当我们增大多项式次数时 我们不难发现 

训练误差明显下降 

这里我写上J下标train 来表示训练集误差 因为随着我们对数据拟合 所需多项式次数的增大 训练误差是趋于下降的 接下来我们再看交叉验证误差 事实上如果我们观察测试集误差的话 我们会得到一个和交叉验证误差 非常接近的结果 所以 我们知道 如果d等于1的话 意味着用一个很简单的函数来拟合数据 此时我们不能很好地拟合训练集(欠拟合) 也就是说 我们会得到 一个较大的交叉验证误差 而如果我们用一个中等大小的 多项式次数来拟合时 在前一张幻灯片中 我们用的d等于2 

那么我们会得到一个 更小的交叉验证误差 因为我们找了一个能够更好拟合数据的次数 同样地 反过来 如果次数d太大 比如说d的值取为4 那么我们又过拟合了 我们又会得到一个较大的交叉验证误差 因此 如果你平稳地过渡这几个点 你可以绘制出一条平滑的曲线 就像这样 我用Jcv(θ)来表示 同样地 如果你画出Jtest(θ) 你也将得到一条类似的曲线 

这样一幅图同时也帮助我们 更好地理解偏差和方差的概念 具体来说 假设你得出了一个学习算法 而这个算法并没有表现地 如你期望那么好 

所以你的交叉验证误差或者测试集误差都很大 我们应该如何判断 此时的学习算法 正处于高偏差的问题还是高方差的问题 交叉验证误差比较大的情况 对应着曲线中的这一端 或者这一端 

那么左边的这一端 对应的就是高偏差的问题 也就是你使用了一个 过于小的多项式次数 比如d等于1 但实际上我们需要一个较高的多项式次数来拟合数据 相反地 右边这一端对应的是高方差问题 

也就是说 多项式次数d 对于我们的数据来讲太大了 这幅图也提示了我们 怎样区分这两种情况 具体地说 

对于高偏差的情况 也就是对应欠拟合的情况 我们发现 

交叉验证误差和训练误差 都会很大 因此 如果你的算法 

有偏差问题的话 那么训练集误差 将会比较大 同时你可能会发现 交叉验证集误差也很大 两个误差可能很接近 或者可能验证误差稍大一点 所以如果你看到这样的组合情况 那就表示你的算法 正处于高偏差的问题 

反过来 如果你的算法处于高方差的问题 那么如果你观察这里 我们会发现 Jtrain 

就是训练误差 会很小 也就意味着 你对训练集数据拟合得非常好 而你的交叉验证误差 

假设此时我们最小化的 是平方误差 而反过来 你的交叉验证集误差 

或者说你的交叉验证集 

对应的代价函数的值 将会远远大于训练集误差 这里的双大于符号 是一个数学符号 表示远远大于 用两个大于符号表示 

因此如果你看见这种组合的情况 这就预示着 

你的学习算法可能正处于 高方差和过拟合的情况 同时 区分这两种不同情形 的关键依据是 如果你的算法处于高偏差的情况 那么你的训练集误差会很大 

因为你的假设 

不能很好地拟合训练集数据 而当你处于高方差的问题时 你的训练误差 通常都会很小 并且远远小于交叉验证误差 好的 但愿这节课能让你 更清楚地理解 偏差和方差这两种问题 

在之后几段视频中 我还将对偏差和误差做更多的解释 

但我们之后要关注的 是诊断一个学习算法 是处于高偏差还是高方差的情况 在后面几段视频中我还将向你展示更多细节 

我们将会看到 通过分清一个学习算法是处于高偏差 还是高方差 还是两种情况的结合 这能够更好地指引我们 应该采取什么样的措施 

来提高学习算法的性能表现 【果壳教育无边界字幕组】翻译:所罗门捷列夫 的关键依据是 如果你的算法处于高偏差的情况 那么你的训练集误差会很大 因为你的假设 不能很好地拟合训练集数据 

而当你处于高方差的问题时 你的训练误差 通常都会很小 并且远远小于交叉验证误差 

希望这节课的内容 更清楚地理解 偏差和方差这两种问题 在之后几段视频中 我还将对偏差和误差做更多的解释 但我们之后要关注的 是诊断一个学习算法 是否处于高偏差或高方差的情况 在后面几段视频中我还将向你展示更多细节 我们将会看到 通过分清一个学习算法是处于高偏差 还是高误差 还是两种情况的结合 这能够更好地指引我们 应该采取什么样的措施 来提高学习算法的性能表现 【教育无边界字幕组】翻译/时间轴：所罗门捷列夫 







## 10.5 Regularization and Bias/Variance(正则化与偏差/方差)

0:00
现在你应该已经知道 算法正则化可以有效地防止过拟合 但正则化跟算法的偏差和方差 又有什么关系呢？ 在这段视频中 我想更深入地 探讨一下偏差和方差的问题 讨论一下两者之间 是如何相互影响的 以及和算法的正则化之间的相互关系 
0:22
假如我们要对这样一个高阶多项式进行拟合 为了防止过拟合现象 我们要使用一个正则化项 因此我们试图通过这样一个正则化项 来让参数的值尽可能小 正则化项的求和范围照例取为 j 等于1到 m 而非 j 等于0到 m 然后我们来分析以下三种情形 第一种情形是正则化参数 λ 取一个比较大的值 比如 λ 的值取为10000甚至更大 在这种情况下 所有这些参数 θ1 θ2 θ3 等等 将被大大惩罚 其结果是 这些参数的值将近似等于0 并且假设模型 h(x) 的值将等于或者近似等于 θ0 因此我们最终得到的假设函数 应该是这个样子 近似是一条平滑的直线 因此这个假设处于高偏差 对数据集欠拟合(underfit) 因此一条水平直线 对这个数据集来讲不是一个好的假设 与之对应的另一种情况是 λ值很小 比如说 λ 的值等于0 在这种情况下 如果我们要拟合一个高阶多项式的话 那么我们通常会处于过拟合(overfitting)的情况 在拟合一个高阶多项式时 如果没有进行正则化 或者正则化程度很微小的话 我们通常会得到高方差和过拟合的结果 因为 λ 的值等于0相当于没有正则化项 因此会对假设过拟合 只有当我们取一个中间大小的 既不大也不小的 λ 值时 我们才会得到一组合理的 对数据刚好拟合的 θ 参数值 那么我们应该怎样自动地选择出一个最合适的正则化参数 λ 呢？ 重申一下 我们的模型和学习参数 以及最优化目标是这样的 让我们假设在使用正则化的情形中 定义 Jtrain(θ) 为另一种不同的形式 同样定义为最优化目标 但不使用正则化项 在先前的授课视频中 当我们没有使用正则化时 我们定义的Jtrain(θ) 就是代价函数J(θ) 但当我们使用正则化多出这个 λ 项时 我们就将训练集误差 也就是Jtrain 定义为 训练集数据预测误差的平方求和 或者说是训练集的平均误差平方和 但不考虑正则化项 与此类似 我们来定义交叉验证集误差和测试集误差 和之前一样定义为 对交叉验证集和测试集进行预测的平均误差平方和 总结一下 我们对于训练误差Jtrain Jcv Jtest的定义 都是平均误差平方和 或者准确地说 是训练集 验证集和测试集进行预测 在不使用正则化项时 平均误差平方和的一半 下面就是我们自动选取正则化参数 λ 的方法 通常我的做法是 选取一系列我想要尝试的 λ 值 因此首先我可能考虑不使用正则化的情形 以及一系列我可能会试的值 
1:52
比如说我可能从0.01 0.02 0.04开始 一直试下去 通常我会将步长设为2倍速度增长 直到一个比较大的值 在本例中以两倍步长递增的话 我们最终取值10.24 实际上我们取的是10 但已经非常接近了 因为小数点后的24对最终的结果不会有太大影响 因此 这样我就得到了12个不同的正则化参数 λ 对应的12个不同的模型 当然了 你也可以试小于0.01的值或者大于10的值 但在这里我就不讨论这些情况了 
2:15
得到这12组模型后 接下来我们要做的事情是 选用第一个模型 也就是 λ 等于0 然后最小化我们的代价函数 J(θ) 这样我们就得到了某个参数向量 θ 与之前视频的做法类似 我使用θ上标(1) 来表示第一个参数向量θ 然后我再取第二个模型 λ 等于0.01的模型 
2:29
最小化代价方差 当然现在 λ 等于0.01 
2:33
那么会得到一个完全不同的参数向量 θ 用 θ(2)来表示 同理 接下来我会得到 θ(3) 对应于我的第三个模型 以此类推 一直到最后一个 λ 等于10或10.24的模型 对应 θ(12) 接下来我就可以用交叉验证集来评价这些假设和参数了 因此我可以从第一个模型开始 然后是第二个模型 对每一个不同的正则化参数 λ 进行拟合 然后用交叉验证集来评价每一个模型 
2:58
也即测出每一个参数 θ 在交叉验证集上的平均误差平方和 然后我就选取这12个模型中交叉验证集误差最小的 那个模型作为最终选择 对于本例而言 假如说 最终我选择了 θ(5) 也就是五次多项式 因为此时的交叉验证集误差最小 做完这些 最后 如果我想看看该模型在测试集上的表现 我可以用经过学习得到的模型 θ(5) 来测出它对测试集的预测效果如何 再次重申 这里我们依然是用交叉验证集来拟合模型 这也是为什么我之前预留了一部分数据作为测试集的原因 
3:23
这样我就可以用这部分测试集比较准确地估计出 我的参数向量 θ 对于新样本的泛化能力 这就是模型选择在选取正则化参数 λ 时的应用 在这段视频中我想讲的最后一个问题是 当我们改变正则化参数 λ 的值时 交叉验证集误差和训练集误差 会随之发生怎样的变化 我想提醒一下 我们最初的代价函数 J(θ) 
3:38
但在这里我们把训练误差 定义为不包括正则化项 
3:43
交叉验证集误差也定义为不包括正则化项 我要做的是绘制出 Jtrain和 Jcv 的曲线 表达的是随着我增大正则化项参数 λ 的值 看看我的假设 
3:52
在训练集上的表现如何变化 以及在交叉验证集上表现如何变化 就像我们之前看到的 如果 λ 的值很小 那也就是说我们几乎没有使用正则化 因此我们有很大可能处于过拟合 而如果 λ 的值取的很大的时候 也就是说取值在横坐标的右端 那么由于 λ 的值很大 我们很有可能处于高偏差的问题 所以 如果你画出 Jtrain 和 Jcv 的曲线 你就会发现 当 λ 的值取得很小时 对训练集的拟合相对较好 因为没有使用正则化 
4:19
因此 对于 λ 值很小的情况正则化项可以忽略 你只需要对平方误差求最小值即可 所以当 λ 值很小时 你最终能得到一个值很小的Jtrain 而如果 λ 的值很大时你将处于高偏差问题 不能对训练集很好地拟合 因此你的误差值可能位于这个位置 因此 当 λ 增大时 训练集误差Jtrain的值 会趋于上升 因为 λ 的值比较大时对应着高偏差的问题 
4:46
此时你连训练集都不能很好地拟合 反过来 当 λ 的值取得很小的时候 你的数据能随意地与高次多项式很好地拟合 
4:50
而交叉验证集误差的曲线是这样的 在曲线的右端 当 λ 的值取得很大时 我们会处于欠拟合问题 因此这对应着偏差问题 那么此时交叉验证集误差将会很大 我写在这里 这是交叉验证集误差Jcv(θ) 由于高偏差的原因我们不能很好地拟合 
5:05
我们的假设不能在交叉验证集上表现地比较好 
5:08
而曲线的左端对应的是高方差问题 此时我们的 λ 值取得很小很小 因此我们会对数据过度拟合 所以由于过拟合的原因 交叉验证集误差也会很大 好的 这就是当我们改变正则化参数 λ 的值时 交叉验证集误差和训练集误差随之发生的变化 当然 在中间取的某个 λ 的值 表现得刚好合适 这种情况下表现最好 交叉验证集误差或者测试集误差都很小 当然由于我在这里画的图显得太卡通 也太理想化了 对于真实的数据 你得到的曲线可能比这看起来更凌乱 会有很多的噪声 对某个实际的数据集 你或多或少能看出像这样的一个趋势 通过绘出这条曲线 通过交叉验证集误差的变化趋势 你可以用自己选择出 或者编写程序自动得出 
5:36
能使交叉验证集误差最小的那个点 然后选出那个与之对应的参数 λ 的值 当我在尝试为学习算法选择正则化参数 λ 的时候 我通常都会画出像这样一个图 帮助我更好地理解各种情况 同时也帮助我确认 我选择的正则化参数值到底好不好 希望这节课的内容让你更深入地理解了正则化 以及它对学习算法的偏差和方差的影响 到目前为止你已经从不同角度认识了方差和偏差问题 在下一节视频中我要做的是 基于我们已经介绍过的所有这些概念 将它们结合起来 建立我们的诊断法 也称为学习曲线 这种方法通常被用来诊断一个学习算法 
6:11
到底是处于偏差问题还是方差问题 还是两者都有 【果壳教育无边界字幕组】翻译/时间轴：所罗门捷列夫 假如说 最终我选择了theta(5) 也就是五次多项式 因为此时的交叉验证集误差最小 做完这些 最后 如果我想看看该模型 在测试集上的表现 我可以用经过学习 得到的模型theta(5) 来测出它对测试集的 预测效果如何 再次重申一下 这里我们依然是用 交叉验证集来拟合模型 这也是为什么我之前 预留了一部分数据 作为测试集的原因 这样我就可以用这部分测试集 比较准确地估计出 我的参数向量theta 对于新样本的泛化能力 
6:54
这就是模型选择在选取 正则化参数lambda时的应用 在这段视频中 我想讲的最后一个问题是 当我们改变 正则化参数lambda的值时 交叉验证集误差 和训练集误差会随之 发生怎样的变化 我想提醒一下 我们最初的代价函数J(θ) 原来是这样的形式 但在这里我们把训练误差 
7:20
定义为不包括正则化项 交叉验证集误差 也定义为不包括 正则化项 我要做的是 绘制出Jtrain和Jcv的曲线 随着我增大正则化项参数 lambda的值 看看我的假设 在训练集上的表现如何变化 以及在交叉验证集上 表现如何变化 就像我们之前看到的 如果正则化项参数 lambda的值很小 那也就是说我们几乎没有使用正则化 因此我们有很大可能处于过拟合 
7:59
而如果lambda的值 取的很大的时候 也就是说取值在 横坐标的右端 那么由于lambda的值很大 我们很有可能处于高偏差的问题 所以 如果你画出 Jtrain和Jcv的曲线 你就会发现 当lambda的值取得很小时 对训练集的拟合相对较好 因为没有使用正则化 因此 对于lambda值很小的情况 正则化项基本可以忽略 你只需要对平方误差 做最小化处理即可 所以当lambda值很小时 你最终能得到一个 值很小的Jtrain 而如果lambda的值很大时 你将处于高偏差问题 不能对训练集很好地拟合 因此你的误差值可能位于这个位置 因此 当lambda增大时 训练集误差Jtrain的值 会趋于上升 因为lambda的值比较大时 对应着高偏差的问题 此时你连训练集都不能很好地拟合 反过来 当lambda的值 取得很小的时候 你的数据能随意地与高次多项式 很好地拟合 交叉验证集误差的曲线是这样的 
9:12
在曲线的右端 当lambda的值 取得很大时 我们会处于欠拟合问题 
9:19
也对应着偏差问题 
9:22
那么此时交叉验证集误差 将会很大 我写在这里 这是交叉验证集误差Jcv 由于高偏差的原因我们不能很好地拟合 我们的假设不能在交叉验证集上表现地比较好 
9:38
而曲线的左端对应的是高方差问题 
9:42
此时我们的lambda值 取得很小很小 因此我们会对数据过度拟合 所以由于过拟合的原因 交叉验证集误差Jcv 结果也会很大 
9:53
好的 这就是 
9:56
当我们改变正则化参数 lambda的值时 交叉验证集误差 和训练集误差 随之发生的变化 当然 在中间取的某个 lambda的值 表现得刚好合适 这种情况下表现最好 交叉验证集误差 或者测试集误差都很小 当然由于我在这里画的图 显得太卡通 也太理想化了 
10:24
对于真实的数据 你得到的曲线可能 比这看起来更凌乱 会有很多的噪声 对某个实际的数据集 你或多或少能看出 像这样的一个趋势 通过绘出这条曲线 通过交叉验证集误差的变化趋势 你可以用自己选择出 或者编写程序自动得出 能使交叉验证集误差 最小的那个点 然后选出那个与之对应的 参数lambda的值 当我在尝试为学习算法 选择正则化参数 lambda的时候 我通常都会得出 类似这个图的结果 帮助我更好地理解各种情况 同时也帮助我确认 我选择的正则化参数值 到底好不好 希望这节课的内容 让你更深入地理解了正则化 
11:15
以及它对学习算法的 偏差和方差的影响 
11:19
到目前为止你已经从不同角度 见识了方差和偏差问题 在下一节视频中 我要做的是 基于我们已经浏览过的 所有这些概念 将它们结合起来 建立我们的诊断法 也称为学习曲线 这种方法通常被用来 诊断一个学习算法 到底是处于偏差问题 还是方差问题 还是两者都有【教育无边界字幕组】翻译、校对、审核：所罗门捷列夫 






## 10.6 Learning Curves(学习曲线)








## 10.7 Deciding What to Do Next Revisited(决定接下来做什么)








## Review