# 八、Neural Networks:Learning
===

## Cost Function and Backpropagation(代价函数与反向传播))

## 8.1、Cost Function(代价函数)

假设我们有一个与左图类似的神经网络结构，再假设我们有一个像这样的训练集，其中有m组训练样本$(x^{(i)},y^{(i)})$

$L$ = 神经网络结构的总层数$(L = 4)$  
$S_l$ = 第$L$层的单元数，也就是神经元的数量(不包括第L层的偏差单元)($S_1 = 3，S_2 = 5$,$S_4 = S_l = 4$)  

![8.1.1](http://m.qpic.cn/psb?/V12umJF70r2BEK/QQbEVzJb8xAlZquj7PmZkAKzukBbcuYFfINIWFEb254!/b/dCEBAAAAAAAA&bo=RgPEAQAAAAARB7A!&rf=viewer_4)

我们会考虑两种分类问题  
* 第一种是二元分类，这里的y只能是0或者1，在这种情况下我们会有一个输出单元，  
在这种情况下$S_l$是输出单元的个数，其中的$L$同样代表最后一层的序号，因为这就是这个网络结构种的层数，所以我们在输出层中单元数目就将是1，为了方便我们把K设置为1，你也可以把K当成输出层的单元数目

* 第二种是多类别分类问题，也就是说会有K个不同的类和输出单元，我们的假设会输出K维向量同时输出单元的个数$S_l=K$ 

接下来我们要定义代价函数：

$$J(\theta) = -\frac{1}{m} \begin{bmatrix}
    \sum_{i=1}^m y^{(i)}logh_\theta(x^{(i)}+(1-y^{(i)})log(1-h_\theta(x^{(i)}))
\end{bmatrix} + \frac{\lambda}{2m}\sum_{j=1}^n\theta^2_j
$$

我们在神经网络中使用的代价函数其实是逻辑回归中使用的代价函数的一般形式，对逻辑回归函数来说我们通常使代价函数$J(\theta)$最小化

与原本的逻辑回归不同的是我们对每一个代价函数都有K个输入单元。

我们用$(h_\Theta(x))_i$来表示第i个输出，$h(x)$是一个K维向量，下标i表示选择输出神经网络输出向量中的第i个元素。

现在的代价函数

$$J(\theta) = -\frac{1}{m} \left[
    \sum_{i=1}^m \sum_{k=1}^K y^{(i)}_k log(h_\theta(x^{(i)}))_k+(1-y^{(i)}_k)log(1-(h_\Theta(x^{(i)}))_k)
\right] + \frac{\lambda}{2m}\sum_{l=1}^{L-1} \sum_{i=1}^{S_l} \sum_{j=1}^{S_l+1} (\Theta^{(l)}_{ji})^2
$$

最末尾附加的项就是类似于我们在逻辑回归里所用的正则化项



## 8.2、Backpropagation Algorithm(反向传播算法)

之前我们在计算神经网络预测结果的时候我们采用了一种正向传播方法。

![8.2.1正向传播](http://m.qpic.cn/psb?/V12umJF70r2BEK/cLUx0dqhZdUpiPufzrf5fluyvYnalAw*m004bcwFtJw!/b/dCEBAAAAAAAA&bo=7QKZAQAAAAARB0c!&rf=viewer_4)

我们从第一层开始正向一层一层进行计算$J(\theta)$和偏导项$\frac{\partial}{\partial\Theta^{(l)}_{ij}}J\left(\Theta\right)$，直到最后一层的$h_{\theta}\left(x\right)$。

现在，为了计算代价函数的偏导数$\frac{\partial}{\partial\Theta^{(l)}_{ij}}J\left(\Theta\right)$，我们需要采用一种反向传播算法，也就是首先计算最后一层的误差，然后再一层一层反向求出各层的误差，直到倒数第二层。 以一个例子来说明反向传播算法。

从直观上说就是对每一个结点，我们计算这样一项$\delta{(l)}_j$,代表了第l层第j个结点的激活值误差

![8.2.2](http://m.qpic.cn/psb?/V12umJF70r2BEK/ODJthqdaJ*IqSkYpQ73bkRYLD839rLHmjTFzoBbSW5I!/b/dCIBAAAAAAAA&bo=HwPAAQAAAAARF*0!&rf=viewer_4)

我们用右边这个有四层的神经网络结构做例子,所以这里的L是4,对每一个输入单元我们都要计算$\delta$项,所以最后一层(第四层)的第j个单元的$\delta^{(4)}_j = a^{(4)}_j - y_j$,即这个单元的激活值(假设$h_\Theta(x)$的输出值)减去训练样本里的真实值.

接下来我们要计算网络中前面几层的误差项$\delta$

下面这个就是计算$\delta$的公式

$\delta^{(4)}=a^{(4)}-y$ 

我们利用这个误差值来计算前一层的误差：

$$\delta^{(3)}=\left({\Theta^{(3)}}\right)^{T}\delta^{(4)}·\ast g'\left(z^{(3)}\right)$$

$$\delta^{(2)}=\left({\Theta^{(2)}}\right)^{T}\delta^{(3)}·\ast g'\left(z^{(2)}\right)$$

其中 $g'(z^{(3)})$是 $S$ 形函数的导数，$g'(z^{(3)})=a^{(3)}\ast(1-a^{(3)})$。而$(θ^{(3)})^{T}\delta^{(4)}$则是权重导致的误差的和。

下一步是继续计算第二层的误差： $\delta^{(2)}=(\Theta^{(2)})^{T}\delta^{(3)}\ast g'(z^{(2)})$ 

因为第一层是输入变量，不存在误差。我们有了所有的误差的表达式后，便可以计算代价函数的偏导数了，假设$λ=0$，即我们不做任何正则化处理时有： $\frac{\partial}{\partial\Theta_{ij}^{(l)}}J(\Theta)=a_{j}^{(l)} \delta_{i}^{l+1}$

反向传播法这个名字源于我们从输出层开始计算$\delta$项,然后我们返回到上一层计算第三隐藏层$\delta$项,接着我们再往前一步来计算$\delta(2)$,我们是类似于把输出层的误差反向传播给了第3层,然后再传到第二层，这就是反向传播的意思.

重要的是清楚地知道上面式子中上下标的含义：

$l$ 代表目前所计算的是第几层。

$j$ 代表目前计算层中的激活单元的下标，也将是下一层的第$j$个输入变量的下标。

$i$ 代表下一层中误差单元的下标，是受到权重矩阵中第$i$行影响的下一层中的误差单元的下标。


假设我们有一个m个样本的训练集，我们先要固定这些带下标ij的$\Delta_{ij}^{(l)}$,他们会被用来计算$\frac{\partial}{\partial\Theta_{ij}^{(l)}}J(\Theta)$偏导项,这些$\delta$会被作为累加项慢慢地增加,以算出这些偏导数.

接下来我们将循环遍历我们的训练集

![8.2.3](http://m.qpic.cn/psb?/V12umJF70r2BEK/GzKe0kC1XT.KAPOZwgVzh8FBYcYNa5yBcxCIInA8KXk!/b/dCEBAAAAAAAA&bo=BwOrAQAAAAARF44!&rf=viewer_4)

我们将取训练样本$(x^{(i)},y^{(i)})$,然后设置$a^{(1)}$也就是输入层的激活函数为$x^{(i)}$(第i个训练样本的输入值),我们先用正向传播算法运算出所有的激活项$a^{(l)}$。然后用我们这个样本的输出值$y^{(i)}$来计算这个输出值所对应的误差项$\delta(L) = a^{(L)}-y^{(i)}$,最后运用反向传播算法计算预测结果与训练集结果的误差$\delta^{(L-1)},\delta^{(L-2)},...,\delta^{(2)}$,没有$\delta^{(2)}$因为我们不需要对输入层考虑误差项，然后利用该误差运用反向传播法($\Delta^{(l)}_{ij} := \Delta^{(l)}_{ij}+a^{(l)}_j\delta^{(l+1)}_i$)计算出直至第二层的所有误差。当然也可以把最后一步的算法改成向量形式$\Delta^{(l)} := \Delta^{(l)}+\delta^{(l+1)}(a^{(l)})^T$

在求出了$\Delta_{ij}^{(l)}$之后，我们便可以计算代价函数的偏导数了，计算方法如下：

$D_{ij}^{(l)} :=\frac{1}{m}\Delta_{ij}^{(l)}+\lambda\Theta_{ij}^{(l)}$ ${if}; j \neq 0$

$D_{ij}^{(l)} :=\frac{1}{m}\Delta_{ij}^{(l)}$ ${if}; j = 0$

最后的最后

$$\frac{\partial}{\partial\Theta_{ij}^{(l)}}J(\Theta) = D^{(l)}_{ij}$$

在Octave 中，如果我们要使用 fminuc这样的优化算法来求解求出权重矩阵，我们需要将矩阵首先展开成为向量，在利用算法求出最优解后再重新转换回矩阵。 




## 8.3、Backpropagation Intuition(理解反向传播)

为了更好地理解反向传播算法，我们再来仔细研究一下前向传播的原理：

前向传播算法：

![8.3.1](http://m.qpic.cn/psb?/V12umJF70r2BEK/md4NJfPaWTEppgbNIAyuVC4IU3BKgJHLxM6TbJTpyYQ!/b/dCIBAAAAAAAA&bo=KQO.AQAAAAARF7U!&rf=viewer_4)

在进行向前传播时，我们肯有些特定的样本,如$(x^{(i)},y^{(i)})$
我们把x^{(i)}放进输入层，他们时我们为输入层设置的值,当对其进行前向传播,传播到第一个隐藏层时,我们要计算出$z^{(2)}_1$和$z^{(2)}_2$，他们是输入单元的加权和，然后我们将sigmoid逻辑函数还有sigmoid激活函数应用到z值上,得到这些激活值$a^{(2)}_1$ 和 $a^{(2)}_2$,然后继续向前传播,最后得到$a^{(4)}_1$,也就是神经网络的最后的输出值



反向传播算法做法

![8.3.2](http://m.qpic.cn/psb?/V12umJF70r2BEK/uxFzNl5Oi5QB3r.CgNIpqODfFVpPo*RpXk65O5Tw.Y8!/b/dCEBAAAAAAAA&bo=LwPEAQAAAAARF8k!&rf=viewer_4)

我们关注一下下面的这个样本$x^{(i)}$和$y^{(i)}$，因为只有一个输出单元，所以忽略正则化项，剩下的代价函数对应了第i个训练样本,即代价函数所对应的训练样本$(x^{(i)},y^{(i)})$,所以第i对样本的代价函数可以写成$cost(i)$的形式,它扮演了一个类似方差的角色，你也可以把cost(i)看出下面的形式

$$cost(i) ≈ (h_\Theta(x^{(i)})-y^{(i)})^2 $$

即神经网络的输出值与实际值的方差

再回看反向传播的过程

![8.3.3](http://m.qpic.cn/psb?/V12umJF70r2BEK/mvEuMBCmZ4jn0UW.1DnoeRZKVe1j2*19KrXiFxGYtRQ!/b/dCIBAAAAAAAA&bo=RAPgAQAAAAARB5Y!&rf=viewer_4)

一种直观地理解是反向传播算法就是在计算$\delta^{(l)}_j$项，我们可以把它看作是我们在第l层中第j个单元中得到的激活项的“误差”.

更正式一点的说法是，$\delta^{(l)}_j$项实际上是代价函数$cost(i)$关于$z^{(l)}_j$的偏导数,也就是计算出的z项的加权和,或者说代价函数关于z项的偏导数,具体来说这个代价函数是一个关于标签y和神经网络中$h(x)$的输出值的函数.

$\delta$项实际上是代价函数关于这些所计算出的中间项的偏导数，他们衡量的是，为了影响这些中间值，我们想要改变神经网络中的权重的程度进而影响整个神经网络的输出$h(x)$并影响所有的代价函数

易知：
$\delta^{(4)}_1 = y^{(i)}-a^{(4)}_1$

求出输出项的误差值后对其进行反向传播,得出第3层的误差,然后传到第2层得到第2层的误差.

而反向传播的计算过程实际上就是后一层的$\delta$项的加权和由对应边的强度来进行加权,即

$$\delta^{(2)}_2 = \Theta^{(2)}_{12}\delta^{(3)}_1+\Theta^{(2)}_{22}\delta^{(3)}_2$$






## Backpropagation in Practice()

## 8.4、Implementation Note:Unrolling Parameters(使用注意：展开参数)

怎样把你的参数 从矩阵展开成向量 以便我们在高级最优化步骤中的使用需要 

![8.4.1](http://m.qpic.cn/psb?/V12umJF70r2BEK/o4bVG9TMXc4mz62Lz981oXDZ0OpVP81yCy1j98CzFBo!/b/dCIBAAAAAAAA&bo=WAPPAQAAAAARB6U!&rf=viewer_4)

具体来讲 你执行了代价函数costFunction 输入参数是theta 函数返回值是代价函数以及导数值 

然后你可以将返回值 传递给高级最优化算法fminunc 顺便提醒 fminunc并不是唯一的算法 你也可以使用别的优化算法 

但它们的功能 都是取出这些输入值 @costFunction 以及theta值的一些初始值 

并且这些程序 都假设theta 和这些theta初始值 都是**参数向量** 也许是n或者n+1阶 但它们都是向量 同时假设这个代价函数 第二个返回值 也就是gradient值 也是n阶或者n+1阶 所以它也是一个向量 这部分在我们使用逻辑回归的时候 运行顺利 但现在 对于神经网络 我们的参数将不再是 向量 而是矩阵了 

因此对于一个完整的神经网络 我们的参数矩阵为θ(1) θ(2) θ(3) 在Octave中我们可以设为 矩阵Theta1 Theta2 Theta3 类似的 这些梯度项gradient 也是需要得到的返回值 那么在之前的视频中 我们演示了如何计算 这些梯度矩阵 它们是D(1) D(2) D(3) 在Octave中 我们用矩阵D1 D2 D3来表示 

怎样取出这些矩阵 并且将它们展开成向量 以便它们最终 成为恰当的格式 能够传入这里的Theta 并且得到正确的梯度返回值gradient 

具体来说 假设我们有这样一个神经网络 其输入层有10个输入单元 隐藏层有10个单元 最后的输出层 只有一个输出单元 因此s1等于第一层的单元数 s2等于第二层的单元数 s3等于第三层的 单元个数 在这种情况下 矩阵θ的维度 和矩阵D的维度 将由这些表达式确定 比如说 θ(1)是一个10x11的矩阵 以此类推 

![8.4.2](http://m.qpic.cn/psb?/V12umJF70r2BEK/8xzoj1IzPMKWEwNuGGXywGsye.CaEE6vaMl4NtWdj00!/b/dCEBAAAAAAAA&bo=VwPMAQAAAAARF7k!&rf=viewer_4)

因此 在Octave中 如果你想将这些矩阵 转化为向量 那么你要做的 是取出你的Theta1 Theta2 Theta3 然后使用这段代码 这段代码将取出 三个θ矩阵中的所有元素 也就是说取出Theta1 的所有元素 Theta2的所有元素 Theta3的所有元素 然后把它们全部展开 成为一个很长的向量 

也就是thetaVec 

同样的 第二段代码 将取出D矩阵的所有元素 然后展开 成为一个长向量 被叫做DVec 最后 如果你想从向量表达 返回到矩阵表达式的话 

你要做的是 比如想再得到Theta1 那么取thetaVec 抽出前110个元素 因此 Theta1就有110个元素 因为它应该是一个10x11的矩阵 所以 抽出前110个元素 然后你就可以 reshape矩阵变维命令来重新得到Theta1 同样类似的 要重新得到Theta2矩阵 你需要抽出下一组110个元素并且重新组合 然后对于Theta3 你需要抽出最后11个元素 然后执行reshape命令 重新得到Theta3 


为了使这个过程更形象 下面我们来看怎样将这一方法 应用于我们的学习算法 

假设说你有一些 初始参数值 θ(1) θ(2) θ(3) 我们要做的是 取出这些参数并且将它们 展开为一个长向量 我们称之为initialTheta 然后作为theta参数的初始设置 传入函数fminunc 

我们要做的另一件事是执行代价函数costFunction 

实现算法如下 

![8.4.3](http://m.qpic.cn/psb?/V12umJF70r2BEK/W3.0B0TmGhQ6Gell5BF74jQ.HLHp4vjHsZebAxyyV7s!/b/dCIBAAAAAAAA&bo=ZQNtAQAAAAARFyo!&rf=viewer_4)

代价函数costFunction 将传入参数thetaVec 这也是包含 我所有参数的向量 是将所有的参数展开成一个向量的形式 

因此我要做的第一件事是 我要使用 thetaVec和重组函数reshape 因此我要抽出thetaVec中的元素 然后重组 以得到我的初始参数矩阵 θ(1) θ(2) θ(3) 所以这些是我需要得到的矩阵 因此 这样我就有了 一个使用这些矩阵的 更方便的形式 这样我就能执行前向传播 和反向传播 来计算出导数 以求得代价函数的J(θ) 

最后 我可以取出这些导数值 然后展开它们 让它们保持和我展开的θ值 同样的顺序 我要展开D1 D2 D3 来得到gradientVec 这个值可由我的代价函数返回 它可以以一个向量的形式返回这些导数值 

现在 我想 对怎样进行参数的矩阵表达式 和向量表达式 之间的转换 有了一个更清晰的认识 

使用矩阵表达式 的好处是 当你的参数以矩阵的形式储存时 你在进行正向传播 和反向传播时 你会觉得更加方便 当你将参数储存为矩阵时 一大好处是 充分利用了向量化的实现过程 

相反地 向量表达式的优点是 如果你有像thetaVec或者DVec这样的矩阵 当你使用一些高级的优化算法时 这些算法通常要求 你所有的参数 都要展开成一个长向量的形式 希望通过我们刚才介绍的内容 你能够根据需要 更加轻松地 在两种形式之间转换



## 8.5、Gradient Checking(梯度检测)

在之前几个视频里，我们讨论了如何进行前向传播 以及后向传播，从而计算导数 但，后向传播有很多细节， 这些细节有点复杂 有一个不幸的消息是， 它们有很多细节会导致一些BUG 如果你用梯度下降来计算， 你会发现表面上它可以工作 实际上， J 虽然每次迭代都在下降 但是可能， 仍然你的代码有很多BUG 所以，表面上关于theta的函数J在减小 但是你可能最后得到的结果 实际上有很大的误差 你这时候可能知道，有一些小的BUG导致 这种不好的算法性能表现 所以，怎么办呢 有一个想法叫梯度检验 Gradient Checking 

它能减少这种错误的概率 就我个人而言，每次我使用后向传播 或者类似梯度下降算法，我都会用这种方法 即使是其他比较复杂的模型，我都会做这种检查 如果你这么做，你会对你的模型更有自信 这样，你会更加确信的模型是100%正确的 从我看到的情况，这种方法， 很大程度可以减少错误的可能性.

来看一个例子 假设我们有一个关于theta的函数H 我现在有它的一个值，假设是实数 我们说，我想要估计函数在这个点上的导数，所以该点的导数是等于图像在该点的切线斜率

![8.5.1]()

现在我要从数值上来逼近它的导数，或者说这是一种从数值上来求近似导数的方法.

首先计算出$\theta+\epsilon$,它在$\theta$右边一点点,然后是$\theta-\epsilon$，然后把两点对应的值用直线连起来，我将得到一条直线 我用这个红色线来近似我的导数 恩，真正的斜率是蓝色的线。 所以，你可以看到这是一个很好的近似。 

数学上，这里的红线垂直高度 除以这个水平宽度，就是我们的斜率 .

所以我们可以近似来表示 这是近似的值， 它等于J加上epsilon减去J减去epsilon对应的函数值，除以2倍的epsilon 

$\frac{\partial }{\partial \theta}J(\theta) ≈ \frac{J(\theta - \epsilon)-J(\theta + \epsilon)  }{2\epsilon}$


通常， 这个epsilon非常小，可能就是10的-4次方 而误差值往往很大， 所以近似效果很好。实际上 如果让epsilon无穷小，这就是导数的定义 恩，它就是导数。 所以， 但我们不希望epsilon太小，否则会有计算上的问题 一般来说在10的-4次方比较合适 通常，你可能见到这个类似的公式 恩。 

$$\frac{J(\theta+\epsilon)-J(\theta) }{\epsilon}$$

所以，右边的叫做单侧导数 左边的叫做双侧导数 后者的精确度更高， 当然，一般我们用后者 

所以，具体来说，当你用octave， 你计算近似梯度时候， 我们用的是这个公式。 恩。。就是红色标注的双边导数近似公式，除以的是2倍 所以，我们有一个近似的值 在这个例子，它看起来非常好地近似我们的结果 

现在，我们来看一般的情况 我们说theta是一个向量参数的情况(前面的\theta都是实数) 我们有一个展开的参数版本， 所以，这里theta是从1到n的n维向量。

我们， 可以用近似的方式来进行计算 可以看到，我们列出各个近似的求导公式 theta 1套前面的公式是这样， 如此种种。这里都是偏导数。 只改变theta 1的值，其他的值固定 分母一样，还是2 epsilon 我们现在可以得到我们想要的近似结果 恩， 

![8.5.2]()

所以这个公式组给出了近似的方法 让你能够从数值上去估算代价函数J所关于的任何参数的偏导数

完整地，你可以这样应用。 



我们用octave来数值计算， 比如， 对于i=1:n，其中n是我们参数的个数(参数向量的维度) 一般我们习惯是舒展的向量而不是矩阵 所以theta是神经网络中所有参数的集合  这里设置thetaPlus = theta 之后让第i项增加epsilon 恩，这就等于我们 thetaPlus(i)， theta1, theta2如此种种 thetal ，一直到N 所以，这是thetaPlus的含义 类似的 我们现在也有l 减去epsilon 

最后你会计算出这个gradApprox(i) 然后近似地得到J(\theta)关于\theta_i在这一点的偏导数

这就是我们使用的方法 我们可以用一个循环来写 来检验这个近似计算的结果是不是等于我们的计算结果 也就是反向传播算法计算的梯度 

Dvec就是我们得到的导数 好的， 反向传播是一个非常高效的算法， 针对所有的参数 我们通常做的是数值计算的结果 也就是刚才所做的 确信这是相等的， 应该说非常接近 所以DVec，我们从反向传播得到， 如果得到同一个结果 或者相近的结果，只相差一些小数位 我们很确信这个反向传播的算法是正确的 

如果我代入梯度计算 一些高级的算法 我们会更加确信我们的导数计算是正确的 因此，我们的代码不仅正确，而且在优化上性能很好 

最后，我想总结一下 告诉你梯度检验的相关内容 这是我通常做的事情 首先，使用反向传播来计算，它是很好的算法 这里就是前面介绍的流程 这里的参数我们把矩阵展开成向量 然后 我们使用数值的梯度来检验 

我们要确信这两个方法算出来结果一致 你知道，就差一点 

最后，也是最重要的步骤 就是在你开始学习之前， 一定要关掉我们的梯度检验， 也就是我们讨论的数值计算方法 

原因是这个计算过程， 实际上代价更高，复杂度也很高 这不是一个很好的计算导数的方法 相反，我们前面讨论的反向传播算法 很早以前介绍的内容 你知道D1 D2 D3对于DVEC 相对来说非常高效。 恩 

所以，一旦你检验证明你的算法没有错误 就要把梯度检验关掉 所以，你一定要关掉 在你开始迭代训练之前 对于其他很多优化算法也一样 为了训练你的分类器 具体来说，如果你一定要用数值方法 来计算梯度， 那么你的算法会非常慢。 在你的支付函数的循环过程当中 因为，正如前面所说 我们再重复一下...它很慢 记得，我们这里计算(4)(3)(2)等等 这是我们的反向传播算法 它快得多 所以，再说一遍...检验完了后向传播没有问题 关掉梯度检验，重要的事情说三遍 当你在训练你的算法的时候， 

所以数值的计算， 这是你的检验方法而已。 对我而言，每当我要使用梯度算法，比如后向传播 我都会用梯度检验一下这个算法是否正确 这会让我更加自信我的算法是正确的。 

当我们对一个较为复杂的模型（例如神经网络）使用梯度下降算法时，可能会存在一些不容易察觉的错误，意味着，虽然代价看上去在不断减小，但最终的结果可能并不是最优解。

为了避免这样的问题，我们采取一种叫做梯度的数值检验（Numerical Gradient Checking）方法。这种方法的思想是通过估计梯度值来检验我们计算的导数值是否真的是我们要求的。

对梯度的估计采用的方法是在代价函数上沿着切线的方向选择离两个非常近的点然后计算两个点的平均值用以估计梯度。即对于某个特定的 $\theta$，我们计算出在 $\theta$-$\varepsilon $ 处和 $\theta$+$\varepsilon $ 的代价值（$\varepsilon $是一个非常小的值，通常选取 0.001），然后求两个代价的平均，用以估计在 $\theta$ 处的代价值。

当$\theta$是一个向量时，我们则需要对偏导数进行检验。因为代价函数的偏导数检验只针对一个参数的改变进行检验，下面是一个只针对$\theta_1$进行检验的示例：
$$\frac{\partial}{\partial\theta_1}=\frac{J\left(\theta_1+\varepsilon_1,\theta_2,\theta_3...\theta_n \right)-J \left( \theta_1-\varepsilon_1,\theta_2,\theta_3...\theta_n \right)}{2\varepsilon}$$

最后我们还需要对通过反向传播方法计算出的偏导数进行检验。

根据上面的算法，计算出的偏导数存储在矩阵 $D_{ij}^{(l)}$ 中。检验时，我们要将该矩阵展开成为向量，同时我们也将 $\theta$ 矩阵展开为向量，我们针对每一个 $\theta$ 都计算一个近似的梯度值，将这些值存储于一个近似梯度矩阵中，最终将得出的这个矩阵同 $D_{ij}^{(l)}$ 进行比较。


## 8.6、Random Initialization(随机初始化)

当你使用梯度下降算法， 或者其他高级的优化算法，我们需要为算法设置初始值，对于高级的优化算法。

现在我们假设使用的算法就是梯度下降，通过初值，我们之后一步步通过梯度下降来最小化代价函数J 当然，这里就是求最小值 所以，我们怎么设置呢 能不能就全部是零呢 

这在之前的逻辑回归里可行，全部为零是可以的。

但是如果是一个神经网络，将全部参数初始化为0，将起不到任何作用，以如下的这个神经网络的训练为例子

![8.6.1](http://a2.qpic.cn/psb?/V12umJF70r2BEK/gvvCUmsGkmqMDMVIKIJmIpLHpRioB8.LGaborqWUqRo!/b/dCEBAAAAAAAA&ek=1&kp=1&pt=0&bo=jgPkAQAAAAARF0g!&tl=3&vuin=904260897&tm=1535695200&sce=60-2-2&rf=viewer_4)

如果你把所有的参数都设置为0，可以看到蓝色的权值，全是0 我用红色标记的， 等于0 用绿色标记的也等于0 所以，对于a_1和a_2隐层单元 将会用同一个输入函数计算 结果最后总的得到$a^{(2)}_1 = a^{(2)}_2$

此外，因为这输出的权值,你可以发现他们的误差值也一样 所以，结果$\delta^{(2)}_1 = \delta^{(2)}_2$ 所以，如果继续下去 我们可以发现他满足下述情况

关于这些参数的偏导数，会满足下列条件，神经网络中的代价函数关于这两条蓝色权重的偏导数，这两条偏导数将会相等

$$\frac{\partial}{\partial\Theta^{(1)}_{01}}J(\theta) = \frac{\partial}{\partial\Theta^{(1)}_{02}}J(\theta) $$

这意味着，即使在每一次梯度下降更新中第一条蓝色的权重会被更新为学习率乘左边这个式子，第2条蓝色的权重会被更新为学习率乘右边这个式子，但这就以为着当对这两条蓝色的权重进行梯度下降更新，最后这两个蓝色的参数会相等

$$\Theta^{(1)}_{01} = \Theta^{(1)}_{02}$$

后面两条红色的值和绿色的也一样

每一次更新以后，这两个隐藏单元的每个参数输入都是相等的，也就是说蓝、红、绿色的权重依然相等。

这意味着即使梯度下降进行了一次迭代，但这两个隐藏单元依然以相同的函数作为输入来计算。最后这个神经网络计算不出有趣的函数了。相当于所有的隐藏单元都在计算相同的特征。所有的隐藏单元都以相同的函数作为输入。

这是一种高度冗余的现象，最后的逻辑回归单元本质上只能得到一个特征，因为所有的单元都一样。

这就使得你的神经网络性能下降，且无法去学习任何有趣的东西和更由意义的功能。 



我们之前提到的问题 叫做对称权重问题，也就是所有的权重都是一样的，所以，随机初始化也被称作打破对称 

所以我们进行初始化的操作目的就是 打破对称

因此对于每个$\theta$值我们将其初始化为一个范围在$-\epsilon 到\epsilon$之间的随机值。

![8.6.2](http://m.qpic.cn/psb?/V12umJF70r2BEK/K*asXuGz83rwX2EJt9JPC9PWGMOAcI82P2V4kyPYeEM!/b/dCEBAAAAAAAA&bo=gAPEAQAAAAARF2Y!&rf=viewer_4)
 

为了训练神经网络，应首先要将权重随机初始化为一个接近0的范围在$-\epsilon 到\epsilon$之间的随机值，然后进行反向传播再进行梯度检验最后使用梯度下降或者其他高级优化算法来最小化代价函数J，这个关于参数$\theta$的函数

整个过程从为参数选取一个随机初始化的值开始，这是一种打破对称性的流程。








任何优化算法都需要一些初始的参数。到目前为止我们都是初始所有参数为0，这样的初始方法对于逻辑回归来说是可行的，但是对于神经网络来说是不可行的。如果我们令所有的初始参数都为0，这将意味着我们第二层的所有激活单元都会有相同的值。同理，如果我们初始所有的参数都为一个非0的数，结果也是一样的。

我们通常初始参数为正负ε之间的随机值，假设我们要随机初始一个尺寸为10×11的参数矩阵，代码如下：

Theta1 = rand(10, 11) * (2*eps) – eps





## 8.7、Putting It Together(组合到一起))

我想结合我们所讲的 所有这些内容 来做一个总体的回顾 看看这些零散的内容 相互之间有怎样的联系 以及神经网络学习算法的 总体实现过程 

当我们在训练一个神经网络时 我们要做的第一件事 就是搭建网络的大体框架 这里我说的框架 意思是 神经元之间的连接模式 

![8.7.1](http://a2.qpic.cn/psb?/V12umJF70r2BEK/**IgraJsec8FcAeAG*gEfAaBt97X748EYg9GbIyoDk8!/b/dCEBAAAAAAAA&ek=1&kp=1&pt=0&bo=uwP8AQAAAAARF2U!&tl=3&vuin=904260897&tm=1535698800&sce=60-2-2&rf=viewer_4)

我们可能会从以下几种结构中选择 

第一种神经网络的结构：

包含三个输入单元 五个隐藏单元 和四个输出单元 

第二种神经网络的结构：

三个输入单元作为输入层 两组五个隐藏单元作为隐藏层 四个输出单元的输出层 

然后第三种：

3 5 5 5 其中每个隐藏层包含五个单元 然后是四个输出单元 

这些就是可能选择的结构 你可以选择每一层 多少个隐藏单元 以及可以选择多少个隐藏层 这些都是你构建时的选择 那么我们该如何做出选择呢？ 

首先 我们知道 我们已经定义了输入单元的数量 一旦你确定了特征集$x^{(i)}$ 对应的输入单元数量 也就确定了 也就是等于特征$x^{(i)}$的维度,输入单元数目将会由此确定.

如果你正在进行 多类别分类(multicalss classifications) 那么输出层的单元数目 将会由你分类问题中 所要区分的类别个数确定 

值得提醒的是 如果你的多元分类问题 y的取值范围 是在1到10之间 那么你就有10个可能的分类 

别忘了把你的输出，y 重新写成向量的形式

即 $y = \begin{bmatrix}
    1 \\ 0 \\ 0 \\ \vdots \\ 0
\end{bmatrix}$

所以现在我们的y不是一个数了 我们重新把y写成 这种形式的向量 第二个分类我们可以写成这样的向量 $y = \begin{bmatrix}
    0 \\ 1 \\ 0 \\ \vdots \\ 0
\end{bmatrix}$
所以 比如说 如果要表达 第五个分类 也就是说y等于5 那么在你的神经网络中 就不能直接用 数值5来表达 因为这里的输出层 有十个输出单元 你应该用一个向量 来表示 

这个向量的第五个位置值是1 其它的都是0 所以对于输入单元 和输出单元数目的选择 还是比较容易理解的 


而对于隐藏单元的个数 以及隐藏层的数目 我们有一个默认的规则 那就是只使用单个隐藏层 所以最左边所示的 这种只有一个隐藏层的神经网络 一般来说是最普遍的 
2:34
或者如果你使用 不止一个隐藏层的话 同样我们也有一个默认规则 那就是**每一个隐藏层 通常都应有相同的单元数**

但实际上通常来说 左边这个结构是较为合理的默认结构 

而对于隐藏单元的个数 通常情况下 隐藏单元越多越好 不过 我们需要注意的是 如果有大量隐藏单元 计算量一般会比较大 

并且一般来说 每个隐藏层 所包含的单元数量 还应该和输入x 的维度相匹配 也要和特征的数目匹配，可能隐藏单元的数目 和输入特征的数量相同 或者是它的二倍 或者三倍 四倍 

因此 隐藏单元的数目需要和输入特征数相匹配 一般来说 隐藏单元的数目取为稍大于 输入特征数目 都是可以接受的 

希望这些能够给你 在选择神经网络结构时 提供一些有用的建议和选择的参考 如果你遵循了这些建议 你一般会得到比较好的模型结构




下面我们就来具体介绍 如何实现神经网络的 训练过程 这里一共有六个步骤 

![8.7.2](http://m.qpic.cn/psb?/V12umJF70r2BEK/GytsXgav1498Fvrhqlxa4QmXJIk*ZSF0GuOkD41mv.Q!/b/dCIBAAAAAAAA&bo=pgP*AQAAAAARF3s!&rf=viewer_4)

* 首先 第一步是构建一个 神经网络 然后随机初始化权值 通常我们把权值 初始化为很小的值 接近于零 

* 第二步我们执行前向传播算法 也就是 对于该神经网络的 任意一个输入$x^{(i)}$ 计算出对应的$h(x)$值 也就是一个输出值y的向量 


* 第三步我们通过代码 计算出代价函数J(θ) 

* 第四步我们执行 反向传播算法来算出这些偏导数 或偏微分项 也就是 J(θ)关于参数θ的偏微分 具体来说 我们要对所有训练集数据 使用一个for循环进行遍历 

这是你第一次进行反向传播算法 所以我建议你最好还是 使用一个for循环来完成程序 对每一个训练样本进行迭代 从x(1) y(1)开始 执行前向传播和反向传播算法 以此类推 直到最后一个样本。其实实际上 有复杂的方法可以实现 并不一定要使用for循环 但我非常不推荐 在第一次实现反向传播算法的时候 使用更复杂更高级的方法 

所以具体来讲 我们对所有的 m个训练样本上使用了for循环遍历 

在这个for循环里 我们对每个样本执行 前向和反向算法 

我们把x(i) 传到输入层 然后执行前向传播和反向传播 

这样我们就能得到 该神经网络中 每一层中每一个单元对应的所有这些激励值$a^{(l)}$ 和$\delta$项 接下来 还是在for循环中 

当然这些是octave的代码 括号里是for循环的循环体 我们要计算出这些delta值 也就是用我们之前给出的公式$\Delta^{(l)} := \Delta^{(l)}+\delta^{(l+1)}·(a^{(l)})^T$最后 

外面的部分 计算出的这些delta值 这些累加项 我们将用别的程序 来计算出 这些偏导数项 

那么这些偏导数项 也应该考虑使用 正则化项lambda值 这些公式在前面已经给出 

那么 搞定所有这些内容 现在你就应该已经得到了 计算这些偏导数项的程序了 

![8.7.3](http://m.qpic.cn/psb?/V12umJF70r2BEK/nIEdw6MazrwQaVUIgv7wzTWHVArdSv.tg0De0TED4nw!/b/dCEBAAAAAAAA&bo=lQPwAQAAAAARF0c!&rf=viewer_4)

* 第五步，我要做的就是使用梯度检查 来比较这些 已经计算得到的偏导数项 把用反向传播算法 得到的偏导数值 与用数值方法得到的 估计值进行比较 因此 通过进行梯度检查来 确保两种方法得到基本接近的两个值 

通过梯度检查我们能确保 我们的反向传播算法 得到的结果是正确的 但必须要说明的一点是 我们需要去掉梯度检查的代码 因为梯度检查的计算非常慢 

* 最后 我们就可以 使用一个最优化算法 比如说梯度下降算法 或者说是更加高级的优化方法 比如说BFGS算法 共轭梯度法 或者其他一些已经内置到fminunc函数中的方法 将所有这些优化方法 和反向传播算法相结合 这样我们就能计算出 这些偏导数项的值 


到现在 我们已经知道了 如何去计算代价函数 我们知道了如何使用 反向传播算法来计算偏导数 那么 我们就能使用某个最优化方法 来最小化关于theta的函数值 代价函数J(θ) 

另外顺便提一下 对于神经网络 代价函数 J(θ)是一个非凸函数 就是说不是凸函数 因此理论上是能够停留在 局部最小值的位置 实际上 梯度下降算法 和其他一些高级优化方法 理论上都能收敛于局部最小值 

但一般来讲 这个问题其实 并不是什么要紧的事 尽管我们不能保证 这些优化算法一定会得到 全局最优值 但通常来讲 像梯度下降这类的算法 在最小化代价函数 J(θ)的过程中 还是表现得很不错的 通常能够得到一个很小的局部最小值 尽管这可能不一定是全局最优值 

最后 梯度下降算法 似乎对于神经网络来说还是比较神秘 希望下面这幅图 能让你对梯度下降法在神经网络中的应用 产生一个更直观的理解 

![8.7.4](http://m.qpic.cn/psb?/V12umJF70r2BEK/s6e6LeThCxPcDMEpyJ7DtelOLOh0gX4PzZAFw6LHQRM!/b/dCEBAAAAAAAA&bo=fQP*AQAAAAARF6A!&rf=viewer_4)

这实际上有点类似 我们早先时候解释梯度下降时的思路 我们有某个代价函数 并且在我们的神经网络中 有一系列参数值 这里我只写下了两个参数值 当然实际上 在神经网络里 我们可以有很多的参数值 theta1 theta2 等等 所有的这些都是矩阵 是吧 因此我们参数的维度就会很高了 由于绘图所限 我们不能绘出 更高维度情况的图像 所以这里我们假设 这个神经网络中只有两个参数值 实际上应该有更多参数 

那么 代价函数J(θ) 度量的就是这个神经网络 对训练数据的拟合情况 

所以 如果你取某个参数 比如说这个 下面这点 

在这个点上 J(θ) 的值是非常小的 这一点的位置所对应的 参数theta的情况是 对于大部分 的训练集数据 

我的假设函数的输出 会非常接近于y(i) 那么如果是这样的话 那么我们的代价函数值就会很小 

而反过来 如果我们 取这个值 也就是这个点对应的值 那么对于大部分的训练集样本 该神经网络的输出 应该是远离 y(i)的实际值的 也就是我们在训练集观测到的输出值 因此 像这样的点 右边的这个点 对应的假设就是 神经网络的输出值 在这个训练集上的测试值 应该是远离y(i)的 

因此这一点对应着对训练集拟合得不好的情况 而像这些点 代价函数值很小的点 对应的J(θ)值 是很小的 

因此对应的是 神经网络对训练集数据 拟合得比较好的情况 我想表达的是 如果是这种情况的话 那么J(θ)的值应该是比较小的 

因此梯度下降算法的原理是 我们从某个随机的 初始点开始 比如这一点 它将会不停的往下下降 

那么反向传播算法 的目的就是算出 梯度下降的方向 而梯度下降的过程 就是沿着这个方向 一点点的下降 一直到我们希望得到的点 在这里我们希望找到的就是局部最优点 

所以 当你在执行反向传播算法 并且使用梯度下降 或者 更高级的优化方法时 这幅图片很好地帮你解释了基本的原理 

也就是 试图找到某个最优的参数值 这个值使得 我们神经网络的输出值 与y(i)的实际值 也就是训练集的输出观测值 尽可能的接近 


小结一下使用神经网络时的步骤：

网络结构：第一件要做的事是选择网络结构，即决定选择多少层以及决定每层分别有多少个单元。

第一层的单元数即我们训练集的特征数量。

最后一层的单元数是我们训练集的结果的类的数量。

如果隐藏层数大于1，确保每个隐藏层的单元个数相同，通常情况下隐藏层单元的个数越多越好。

我们真正要决定的是隐藏层的层数和每个中间层的单元数。

训练神经网络：

参数的随机初始化

利用正向传播方法计算所有的$h_{\theta}(x)$

编写计算代价函数 $J$ 的代码

利用反向传播方法计算所有偏导数

利用数值检验方法检验这些偏导数

使用优化算法来最小化代价函数
