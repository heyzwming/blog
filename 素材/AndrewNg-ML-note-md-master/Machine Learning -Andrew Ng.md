机器学习-吴恩达
===


## 章节1 绪论：初识机器学习

### 课时1  欢迎参加《机器学习》课程   06:54
### 课时2  什么是机器学习？   07:14
### 课时3  监督学习   12:29
### 课时4  无监督学习 14:13
### 课时5  问题

## 章节2 单变量线性回归

### 课时6  模型描述   08:10
### 课时7  代价函数   08:12
### 课时8  代价函数（一） 11:09
### 课时9  代价函数（二） 08:48
### 课时10  梯度下降  11:30
### 课时11  梯度下降知识点总结    11:50
### 课时12  线性回归的梯度下降    10:20
### 课时13  本章课程总结

## 章节3 线性回归回顾

### 课时14  矩阵和向量    08:45
### 课时15  加法和标量乘法    06:53
### 课时16  矩阵向量乘法  13:39
### 课时17  矩阵乘法  11:09
### 课时18  矩阵乘法特征  09:02
### 课时19  逆和转置  11:13

## 章节4 配置

### 课时20  安装 MTLAB 并设置编程任务环境
### 课时21  安装 MATLAB
### 课时22  在 Windows 上安装 Octave
### 课时23  在 Mac OS X  上安装 Octave
### 课时24  在 Mac OS X (10.8 Mountain Lion and Earlier) 上安装 Octave
### 课时25  GNU/Linux 上安装 Octave
### 课时26  更多 Octave/MATLAB  资源

## 章节5 多变量线性回归

### 课时27  多功能    08:22
### 课时28  多元梯度下降法    05:04
### 课时29  多元梯度下降法演练 I – 特征缩放   08:52
### 课时30  多元梯度下降法II – 学习率 08:58
### 课时31  特征和多项式回归  07:39
### 课时32  正规方程（区别于迭代方法的直接解法）  16:17
### 课时33  正规方程在矩阵不可逆情况下的解决方法  05:59
### 课时34  完成并提交编程作业    03:33

## 章节6 Octave/Matlab 教程

### 课时35  基本操作  13:59
### 课时36  移动数据  16:07
### 课时37  计算数据  13:15
### 课时38  数据绘制  09:38
### 课时39  控制语句：for，while，if 语句 12:56
### 课时40  矢量  13:48
### 课时41  本章课程总结

## 章节7 Logistic 回归

### 课时42  分类  08:08
### 课时43  假设陈述  07:24
### 课时44  决策界限  14:49
### 课时45  代价函数  10:23
### 课时46  简化代价函数与梯度下降    10:14
### 课时47  高级优化  14:06
### 课时48  多元分类：一对多  06:15
### 课时49  本章课程总结

## 章节8 正则化

### 课时50  过拟合问题    09:42
### 课时51  代价函数  10:10
### 课时52  线性回归的正则化  10:40
### 课时53  Logistic 回归的正则化 08:33

## 章节9 神经网络学习

### 课时54  非线性假设    09:36
### 课时55  神经元与大脑  07:47
### 课时56  模型展示Ⅰ     12:01
### 课时57  模型展示Ⅱ     11:46
### 课时58  例子与直觉理解Ⅰ   07:15
### 课时59  例子与直觉理解Ⅱ   10:20
### 课时60  多元分类  03:51

## 章节10 神经网络参数的反向传播算法

### 课时61  代价函数  06:43
### 课时62  反向传播算法  11:59
### 课时63  理解反向传播  12:44
### 课时64  使用注意：展开参数    07:47
### 课时65  梯度检测  11:37
### 课时66  随机初始化    06:51
### 课时67  组合到一起    13:23
### 课时68  无人驾驶  06:30

## 章节11 应用机器学习的建议

### 课时69  决定下一步做什么  05:50
### 课时70  评估假设  07:35
### 课时71  模型选择和训练、验证、测试集  12:03
### 课时72  诊断偏差与方差    07:42
### 课时73  正则化和偏差、方差    11:20
### 课时74  学习曲线  11:53
### 课时75  决定接下来做什么  06:50

## 章节12 机器学习系统设计

### 课时76  确定执行的优先级  09:29
### 课时77  误差分析  13:12
### 课时78  不对称性分类的误差评估    11:35
### 课时79  精确度和召回率的权衡  14:05
### 课时80  机器学习数据  11:09

## 章节13 支持向量机

### 课时81  优化目标  14:47
### 课时82  直观上对大间隔的理解  10:36
### 课时83  大间隔分类器的数学原理    19:41
### 课时84  核函数1   15:44
### 课时85  核函数2   15:43
### 课时86  使用SVM   21:02

## 章节14 无监督学习

### 课时87  无监督学习    03:17
### 课时88  K-Means算法   12:32
### 课时89  优化目标  07:04
### 课时90  随机初始化    07:49
### 课时91  选取聚类数量  08:22

## 章节15 降维

### 课时92  目标 I：数据压缩  10:09
### 课时93  目标 II：可视化   05:27
### 课时94  主成分分析问题规划1    09:05
### 课时95  主成分分析问题规划2   15:14
### 课时96  压缩重现  03:54
### 课时97  主成分数量选择    10:30
### 课时98  应用 PCA 的建议   12:48

## 章节16 异常检测

### 课时99  问题动机  07:38
### 课时100  高斯分布 10:27
### 课时101  算法 12:02
### 课时102  开发和评估异常检测系统   13:07
### 课时103  异常检测 VS 监督学习 07:36
### 课时104  选择要使用的功能 12:17
### 课时105  多变量高斯分布   13:45
### 课时106  使用多变量高斯分布的异常检测 14:03

## 章节17 推荐系统

### 课时107  问题规划 07:54
### 课时108  基于内容的推荐算法   14:31
### 课时109  协同过滤 10:14
### 课时110  协同过滤算法 08:26
### 课时111  矢量化：低轶矩阵分解 08:27
### 课时112  实施细节：均值规范化 08:30

## 章节18 大规模机器学习

### 课时113  学习大数据集 05:45
### 课时114  随机梯度下降 13:19
### 课时115  Mini-Batch 梯度下降  06:18
### 课时116  随机梯度下降收敛 11:31
### 课时117  在线学习 12:50
### 课时118  减少映射与数据并行   14:08

## 章节19 应用举例：照片OCR（光学字符识别）

### 课时119  问题描述与 OCR pipeline  07:02
### 课时120  滑动窗口 14:40
### 课时121  获取大量数据和人工数据   16:20
### 课时122  天花板分析：下一步工作的 pipeline    13:50

## 章节20 总结与感谢

### 课时123  总结与感谢   13:50
