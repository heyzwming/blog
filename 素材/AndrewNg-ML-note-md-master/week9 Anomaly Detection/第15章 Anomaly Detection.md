十五、Anomaly Detection(异常检测)
===
### Density Estimation()
---
## 15.1、 Problem Motivation(问题规划)

异常检测(Anomaly detection)问题是机器学习算法的一个常见应用 这种算法的一个有趣之处在于它虽然主要用于非监督学习问题 但从某些角度看它又类似于一些监督学习问题 

![15.1.1](http://m.qpic.cn/psb?/V12umJF70r2BEK/TchjYRzgfAMn7uQbHCv6FghqF*l.ZRkQhjtRLysCnCI!/b/dPQAAAAAAAAA&bo=ggPxAQAAAAARF1E!&rf=viewer_4)

那么什么是异常检测呢？举个例子，假设你是一个飞机引擎制造商，当你生产的飞机引擎从生产线上流出时 你需要进行 QA (质量控制测试) ，而作为这个测试的一部分，你测量了飞机引擎的一些特征变量，如引擎运转时产生的热量或者引擎的振动等等,这样一来你就有了一个数据集,从$x_{(1)}$到$x_{(m)}$.将这些数据绘制成图表,看起来就是这个样子,这里的每个叉都是你的无标签数据.

这样 异常检测问题可以定义如下 

我们假设后来有一天你有一个新的飞机引擎从生产线上流出,而你的新飞机引擎有特征变量集$x_test$,所谓的异常检测问题就是我们希望知道这个新的飞机引擎是否有某种异常，或者说我们希望判断这个引擎是否需要进一步测试 

如果你的新引擎对应的点落在绿色的这个点，那么你可以认为它看起来像我们之前的合格的引擎，因此我们可以直接认为它是正常的 然而 如果你的新飞机引擎对应的点$x_test$在这群点的外面 那么我们可以认为这是一个异常 

也许我们需要在向客户发货之前进一步检测这个引擎,因为它和我们之前见过的其他正常飞机引擎看起来不一样 

如果更正式的定义异常检测问题 那么我们有一些数据 从x(1)到x(m) 我们通常假定这m个样本 都是正常的 然后我们需要一个算法来告诉我们 一个新的样本数据x-test是否是异常 我们要采取的方法是给定无标签的训练集 我们将对数据建一个模型p(x) 也就是说 我们将对 x的分布概率建模 其中x是这些特征变量 例如飞机引擎 

![15.1.2](http://m.qpic.cn/psb?/V12umJF70r2BEK/txLwzHRQTeTzjjcfJP4RtMRyYJ0pOet.YJXcCORLIXA!/b/dG0BAAAAAAAA&bo=sAPsAQAAAAARF34!&rf=viewer_4)

因此 当我们 建立了x的概率模型之后 我们就会说 对于新的飞机引擎x-test 如果概率p 低于阈值ε 那么就将其标记为异常 

因此当我们看到一个新的引擎 在我们根据训练数据得到的p(x)模型中 这个点出现的概率非常低时 我们就将其标记为异常 反之 如果x-test的概率p 大于给定的阈值ε 我们就认为它是正常的 

因此 给定图中的 这个训练集 如果你建立了一个模型 你将很可能发现飞机引擎，即模型p(x) 将会认为 在中心区域的这些点 有很大的概率值是正常的，而稍微远离中心区域的点正常的概率会小一些 

更远的地方的点 它们的概率将更小 这外面的点 和这外面的点 将成为异常点 

而这边的点 正好在中心区域的点 这些点将是正常的 因为在中心区域 p(x)概率值会非常大 因为我们看到很多点都落在了这个区域 

异常检测算法有如下应用案例 

![15.1.3](http://m.qpic.cn/psb?/V12umJF70r2BEK/sx2uNH3yHBDf8ArZRRLZBLd6a5SFUYNHJti0xpTBJIE!/b/dIABAAAAAAAA&bo=pgMCAgAAAAARF4U!&rf=viewer_4)

也许异常检测 最常见的应用是 是欺诈检测 假设你有很多用户 你的每个用户 都在从事不同的活动 也许是在你的网站上 也许是在一个实体工厂之类的地方 你可以对不同的用户活动计算特征变量 

然后你可以建立一个模型用来表示用户表现出各种行为的可能性,即用户行为对应的特征向量出现的概率 

因此你看到某个用户在网站上行为的特征变量是这样的 

也许x1是用户登陆的频率 x2也许是用户访问某个页面的次数 或者交易次数 也许x3是 用户在论坛上发贴的次数 x4是 用户的 打字速度 有些网站是可以记录 用户每秒 打了多少个字母的 因此你可以根据这些数据建一个模型p(x) 

最后你将得到 你的模型p(x) 然后你可以用它来发现 你网站上的行为奇怪的用户 你只需要 看哪些用户的p(x)概率小于ε 接下来 你拿来这些用户的档案 做进一步筛选 

或者要求这些用户 验证他们的身份 从而让你的网站防御 异常行为或者欺诈行为 

这样的技术将会找到 行为不寻常的用户 而不只是有欺诈行为的用户 也不只是那些 被盗号的用户 或者有滑稽行为的用户 而是行为不寻常的用户 然而这就是许多在线购物网站常用来识别异常用户的技术 这些用户行为奇怪 可能是表示他们有欺诈行为或者是被盗号 

异常检测的另一个例子是在工业生产领域 事实上 我们之前已经谈到过 飞机引擎的问题 你可以找到异常的飞机引擎 然后要求进一步细查这些引擎的质量 

第三个应用是 数据中心的计算机监控 实际上 我有些朋友正在从事这类工作 如果你管理一个 计算机集群 或者一个数据中心 其中有许多计算机 那么我们可以为每台计算机计算特征变量 也许某些特征衡量 计算机的内存消耗 或者硬盘访问量 CPU负载 或者一些更加复杂的特征 例如一台计算机的CPU负载与网络流量的比值 那么 给定正常情况下数据中心中计算机的特征变量 你可以建立p(x)模型 也就是说你可以建模这些计算机出现不同内存消耗的概率 或者出现不同硬盘访问量的概率 或者不同的CPU负载等等 

然后 如果你有一个计算机 它的概率p(x)非常小 那么你可以认为这个计算机运行不正常 

或许它 即将停机 因此你可以要求系统管理员查看其工作状况 

目前这种技术实际正在被各大数据中心使用 用来监测大量计算机可能发生的异常 

好啦 这就是异常检测算法 

在下一个视频中 我们将介绍一下高斯分布 回顾一下高斯分布 的一些特征 在再下一个视频中 我们将利用高斯分布来推导一个异常检测算法

## 15.2、 Gaussian Distribution(高斯分布)

在这个视频中 我将介绍高斯分布(the Gaussian distribution) 也称为正态分布(normal distribution)

假设x是一个 实数随机变量 因此x是一个实数 如果x的概率分布服从高斯分布,其中均值为μ ,方差为$σ^2$ 那么将它记作 随机变量x~

这个波浪号 读作 服从...分布 为了表示高斯分布 有时你将使用$N(,σ^2)$

高斯分布 有两个参数 一个是均值 我们记作$μ$ 另一个是方差我们记作$σ^2$

![15.2.1](http://m.qpic.cn/psb?/V12umJF70r2BEK/60jS1IC9Ay29xLg.rSIkBj7Wj*K0W5h6OPwJLaZ0fS8!/b/dOAAAAAAAAAA&bo=awPfAQAAAAARF5Y!&rf=viewer_4)

如果我们将高斯分布 的概率密度函数绘制出来 它看起来将是这样一个钟形的曲线 大家之前可能就见过 

这个钟形曲线 有两个参数 分别是μ和σ 其中μ控制 这个钟形曲线 的中心位置 σ控制这个钟形曲线的宽度 

因此 参数σ 有时也称作 一个标准差 

这条钟形曲线决定了x取不同数值的概率密度分布 

因此x取中心这些值的概率相当大 因为高斯分布的概率密度在这里很大 

而x取远处和更远处数值的概率将逐渐降低 直至消失 

高斯分布的数学公式的表示是这样的：
$$p(x|μ,σ^2) = \frac{1}{ (2\pi)^{\frac{1}{2}} \sigma} exp(-\frac{(x-μ)^2}{2\sigma^2})$$
 
左边这幅图的这条曲线其实就是给定$μ$以及$σ^2$,p(x)的函数图像 

也许有些时候我们使用方差会更方便 但有时候我们用σ^2，而σ被称作 标准差(the standard deviation) 它确定了 高斯分布概率密度函数 的宽度 而$σ^2$则称作方差 

让我们看几个高斯分布的图像 

![15.2.2](http://m.qpic.cn/psb?/V12umJF70r2BEK/PS6QDR7IvquZ*z1VKLv7jpsEjhMJoFZZ*EP*pY3XZn4!/b/dPQAAAAAAAAA&bo=YwPhAQAAAAARF6A!&rf=viewer_4)

如果μ取0 σ取1 那么这将对应一个以0为中心的高斯分布 而高斯分布的宽度 由标准差σ决定 

再看一些μ=0， σ=0.5、μ=0，σ=2的例子


接下来 让我们来看参数估计问题 

![15.2.3](http://a3.qpic.cn/psb?/V12umJF70r2BEK/ZUbDIzl6O*WVTKmv*SMvSfSVJwQPIfzfvfPktOtDyKU!/b/dN4AAAAAAAAA&ek=1&kp=1&pt=0&bo=nQX2AgAAAAARF0w!&tl=3&vuin=904260897&tm=1536289200&sce=60-2-2&rf=viewer_4)

那么 什么是参数估计问题？ 假设我们有一个有m个样本的数据集 从$x^{(1)}$到$x^{(m)}$ 假设他们都是实数 在这幅图里 我画出了整个数据集 图中的横轴 是x轴 我的样本x取值分布广泛 我就将它们画在这里 而参数估计问题就是 假设我猜测这些样本 来自一个高斯分布的总体 每一个样本xi服从某个分布 因此 我猜测这里的每个样本服从正态分布或者高斯分布 它有两个参数μ和σ平方 然而我不知道这些参数的值是多少 

参数估计问题就是给定数据集 我希望能找到能够估算出μ和σ平方的值 

因此如果你有这样一个数据,我试图找到它来自哪个高斯分布 

也许这个就是它对应的高斯分布 

其中μ对应分布函数的中心 而标准差σ控制高斯分布的宽度 这条曲线似乎很好的拟合了数据 因为看起来这个数据集 在中心区域的概率比较大 而在边缘的概率越来越小 因此 也许这是 对μ和σ平方 的一个不错的估计 也就是说 我们的数据对应这样一个高斯分布 

那么 接下来我将写下对μ和σ平方进行参数估计的标准公式 我们估计μ的方法是 对我的 所有样本 求平均值 μ就是平均值参数 因此 我将 使用我的训练集 使用我的m个样本 对它们取平均 这样我就得到了高斯分布的中心位置 

$$μ = \frac{1}{m}\sum^m_{i=1}x^{(i)}$$

那么如何估计σ平方呢？ σ平方表示方差 我们也来写下方差的标准计算公式 

$$\sigma^2 = \frac{1}{m}\sum^m_{i=1}(x^{(i)}-μ)^2$$

而方差的含义就是所有样本的差值平方和再求平均。

在极大似然估计(maximum likelihood estimation)里的估计 实际就是对μ和σ^2 的极大似然估计

如何估计高斯分布中的参数μ和σ平方 只要你有一个训练集 如果你猜测它来自一个高斯分布 你就可以估计出它的参数值μ和σ平方 



## 15.3、 Algorithm(算法)

本节中 我将应用高斯分布开发异常检测算法 

假如说我们有一个无标签的训练集 共有m个训练样本 并且这里的训练集里的每一个样本 都是n维的特征 因此你的训练集应该是 m 个 n 维的特征构成的样本矩阵 比如 m 个飞机引擎产品的样本 或者是 来自 m 个用户或者其它的什么东西 

现在 我们解决异常检测的方法是 我们要从数据中 建立一个 p(x) 概率模型 我们要尝试计算出这些哪些特征出现的概率比较高 哪些特征的概率较低 

![15.3.1](http://a3.qpic.cn/psb?/V12umJF70r2BEK/H3vnA*mkkhcjVzaxtul95HHi5xU0rIDExGWs1fwz6kk!/b/dNoAAAAAAAAA&ek=1&kp=1&pt=0&bo=tgUAAwAAAAARF5A!&tl=3&vuin=904260897&tm=1536300000&sce=60-2-2&rf=viewer_4)

因此 x 是一个向量 我们要做的事情是 建立一个 p(x) 的模型 表示 x1 的概率,同时假设每一个样本都是分散的且服从高斯正态分布，$x^{(i)} 服从 (μ_i,σ_i^2)$，这样就可以得到如下的模型。

$$p(x) = p(x_1|μ_1,σ_1^2)p(x_2|μ_2,σ_2^2)p(x_3|μ_3,σ_3^2)...p(x_n|μ_n,σ_n^2)$$ 

这就是我要说的模型 

最后 做一个总结 让我把这些式子写得紧凑点 我可以把这个式子 写成一个乘积式 

$$p(x) = \prod_{j=1}^n p(x_j|μ_j,σ_j^2)$$

这里用连乘的符号 这个表达式表示从等于 j=1 开始一直乘到 j=n 这样写看起来更紧凑 

顺便要说的是 估计 p(x) 的分布问题 这种问题通常被称为密度估计(Density estimation)问题 

整理一下，下面便是我们的异常检测算法 

![15.3.2](http://a1.qpic.cn/psb?/V12umJF70r2BEK/RoOfPhCRXsgErTrkJ1XGKaVms4xQ2OOWWjIFx1eRHbw!/b/dPQAAAAAAAAA&ek=1&kp=1&pt=0&bo=rQUHAwAAAAARF4w!&tl=3&vuin=904260897&tm=1536300000&sce=60-2-2&rf=viewer_4)

第一步便是选择特征或者是找出一些 我们认为的具有比较反常样本的特征xi, 这个特征可能会呈现一个特别大的数值 或者特别小的数值,因为这个看起来本身就有些异常 但更为普遍的是 尽可能尝试选择能够描述你所想的能够描述你所搜集的数据的一般特性的特征

下一步 给出一组  m 个无标签数据构成的训练集,从 x(1) 到 x(m)。

之后我们要根据公式进行参数拟合 μ1 到 μn 以及方差值 (σ1)^2 到 (σn)^2 

同时也可以用向量化的方法写出参数$μ$和$σ_j^2$

$$μ = \begin{bmatrix}
    μ_1 \\
    μ_2 \\
    \vdots \\
    μ_n
\end{bmatrix} = \frac{1}{m} \sum^m_{i=1}x^{(i)}$$

最后 当给出一个新样本时 比如当有一个新的飞机引擎时 你想要知道这个飞机引擎是否出现异常 

我们要做的就是 计算出这个案例中的概率 p(x)是多少呢 

我们知道 p(x) 的值 等于这个乘积式 

$$p(x) = \prod^n_{j=1}p(x_j|μ_j,σ^2_j) = \prod^n_{j=1}\frac{1}{\sqrt{2\pi}σ_j}exp(-\frac{(x_j-μ_j)^2}{2σ^2_j}) $$

如果通过这个公式计算出的概率很小，P(x) < $\epsilon$，那么就将这一项标注为异常

在这节中我们也给出了通过给出的数据集拟合参数进行参数估计得到参数μ和σs然后检测新的样本确定新样本是否是异常 这一系列完整的过程 



### Building an Anomaly Detection System()
---
## 15.4、 Developing and Evaluating an Anomaly Detection System(开发和评估异常检测系统)

如何开发一个关于异常检测的应用来解决一个实际问题 具体来说 我们将重点关注如何评价一个异常检测算法,在前面我们已经提过使用实数评价法的重要性，当你在用某个学习算法来开发一个具体的机器学习应用时 你可以通过这个实数评价法返回的数字来判断你的决定或者参数等的选择的好坏

![1](http://a1.qpic.cn/psb?/V12umJF70r2BEK/VPRXcCMhv0aANYboVdJUYHuIq8345pIo5mND763QidA!/b/dGwBAAAAAAAA&ek=1&kp=1&pt=0&bo=lAUFAwAAAAARF7c!&tl=3&vuin=904260897&tm=1536303600&sce=60-2-2&rf=viewer_4)

为了能评价一个异常检测系统 我们先假定一些已有了标签的异常和正常的数据。以飞机发动机的为例，现在假如你有了一些带标签数据也就是明确知道有异常的飞机引擎的样本和明确知道没有异常的引擎样本。 

用 y=0 来表示那些完全正常的样本  
用 y=1 来代表那些异常样本 

那么异常检测算法的开发过程以及评估方法如下所示

我们把大量无异常的(但可能有一些异常的)数据分配到你的训练集里，用来训练p(x)，

然后，我们以一个占比稍小的混合了正常数据和异常数据的子数据集来作交叉验证集和测试集（通常会有更多的正常样本）

![2](http://m.qpic.cn/psb?/V12umJF70r2BEK/zkObyNIOeHwQa7pC8o7qCv20aHToFp7uMN50oEq7wyA!/b/dPQAAAAAAAAA&bo=sQP7AQAAAAARF2g!&rf=viewer_4)

例如，我们有一个数据集(通常以6：2：2的比例分配)，其中0.2%的样本是异常的。我们把占总样本60%那么多的正常样本（y=0）取出来当作训练集来拟合p(x) 也就是p(x_1|μ_1,σ^2)一直到p(x_n| μ_n, σ_n^2)，估计参数  μ_1, σ_1,...,μ_n, σ_n。然后我们另取20%样本来作交叉验证集（其中有占总样本0.1%的异常样本），剩下20%的样本来作测试集（其中有占总样本0.1%的异常样本）。
换句话说，我们将数据集分割成了60%/20%/20%分别作为训练集、交叉验证集、测试集，并且异常样本的50%/50%分别放在交叉验证集和训练集中。

给出之前分好的训练集、交叉验证集和测试集 异常检测算法的推导和评估方法如下 

首先 我们使用高斯函数/模型，来拟合m个无标签的训练样本 来拟合模型p(x) ( 假设都是正常的飞机引擎 )

然后给出交叉验证集或者测试集中的某个测试样本(x……{(i)}_test, y^{(i)}_test) 假设这个算法对 p(x)<ε 的情况作出的 预测为 y=1 而p(x)≥ε时 算法作出的预测为 y=0 

所以现在 我们可以把 异常检测算法想成是 对交叉验证集 和测试集中的y 进行一个预测 

当然 这些标签会比较偏斜 因为y=0 也就是正常的样本 肯定是比出现 y=1 也就是异常样本 的情况更多

这跟我们在监督学习中 用到的评价度量 方法非常接近 

那么用什么评价度量好呢？ 因为数据是非常偏斜的 因为y=0是 更加常见的 因此分类准确度不是一个好的度量法，如果你有一个 比较偏斜的数据集 那么总是预测y=0 它的分类准确度自然会很高 

![3](http://m.qpic.cn/psb?/V12umJF70r2BEK/witDOAKxA.Hc1YCx34pnfPbGJ659L7Y0.LrbGjDVqjU!/b/dN8AAAAAAAAA&bo=pAX9AgAAAAARF34!&rf=viewer_4)

取而代之的，正确的性能指标可以参考下面的这些

* 真阳性(True positive)、假阳性(false positive)、 假阴性(false negative)和真阴性(true negative)的比率 

* 精度(Precision)和召回率 

* F1-积分(score) 

通过这些方法 你就可以评价你的异常检测算法在交叉验证和测试集样本中的表现 

最后一点 之前在 异常检测算法中 我们有一个参数ε,这个ε是我们用来决 什么时候把一个样本当作是异常样本的阈值 

所以 如果你有 一组交叉验证集样本 一种选择参数ε的方法 就是你可以试一试 多个不同的 ε的取值 然后选出一个 使得F1-积分的值最大的那个ε 也就是在交叉验证集中表现最好的 

更一般来说 我们使用训练集、测试集 和交叉验证集的方法是 

当我们需要作出决定时 比如要包括哪些特征 或者说要确定参数ε取多大合适 我们就可以 不断地用交叉验证集 来评价这个算法 然后决定我们应该 用哪些特征 怎样选择ε,当我们找到了能符合我们要求的ε的值后,我们就能用最终的模型来评价这个算法或者说用测试集来最终评价算法的表现 


## 15.5、 Anomaly Detection vs. Supervised Learning(异常检测 vs 监督学习)



---
我们有这样一个问题： 异常检测也是使用了这些带标签的数据(异常y=1和正常y=0) 那我们为什么我们不直接用监督学习的方法呢？

那么我们什么时候应该用异常检测算法和监督学习算法是更有成效的？

![15.5.1](http://m.qpic.cn/psb?/V12umJF70r2BEK/H4gAscL4hFYq.EVGvFnUAmw3cN.3kwYmtrM7brmqBp8!/b/dAkBAAAAAAAA&bo=rgUPAwAAAAARF4c!&rf=viewer_4)

在下列情况中使用异常检测算法：

* 我们拥有很少(0-20-50)的positive正样本和大量的negative负样本(我们可以把这些正样本存为交叉验证集和测试集,以便使用大量负样本训练拟合p(x)模型)

* 我们有愈多不同“类型(type)”的异常，并且任何算法都很难从positive样本中知道异常是什么样的，未来出现的异常可能和我们现在已知的任何异常都不一样。


在下列情况下使用监督学习算法：

* 我们同时拥有很多的positive样本与negative样本。换句话说，训练集里的比例分配更均匀。

* 我们有足够多的positive样本来预测新的positive样本是什么样的。未来出现的positive样本和训练集里已知的会很相似


关键的区别就是 在异常检测算法中 我们只有一小撮正样本，因此学习算法不可能从这些正样本中学出太多东西 因此取而代之的是我们使用一组大量的负样本 这样样本就能学到更多 或者说能从大量的负样本 比如大量的正常引擎样本中学出 p(x) 模型 另外我们预留一小部分正样本来评价我们的算法 既用于交叉验证集也用于测试集 

另外再额外说一点 关于这些不同类型的异常情况 如垃圾邮件的例子 在那些例子中 垃圾邮件的类型其实也有很多种 有的是想卖东西给你 有的是想钓出你的密码 这种就叫钓鱼邮件 还有其他一些类型的垃圾邮件 但对于垃圾邮件的问题 我们通常有足够多的垃圾邮件的样本 我们能得到绝大多数不同类型的垃圾邮件 因为我们有大量的垃圾邮件样本的集合 因此这也是为什么我们通常把垃圾邮件问题看作是 监督学习问题的原因 虽然垃圾邮件的种类 通常有太多太多 

因此我们可以看看一些异常检测的应用和监督学习应用的比较 

![15.5.2](http://a1.qpic.cn/psb?/V12umJF70r2BEK/KUfKbLZxuT8OyEsRZwdpdOi0zpJ4TU2iU3S8OKRsqc4!/b/dPQAAAAAAAAA&ek=1&kp=1&pt=0&bo=VQUYAgAAAAARF2o!&tl=3&vuin=904260897&tm=1536375600&sce=60-2-2&rf=viewer_4)

我们不难发现 对于欺诈检测(fraud detection) 如果你掌握了许多种不同类型的诈骗方法 并且相对较小的训练集 很少的一些你网站上出现的欺诈用户 那我会使用异常检测算法 

如果你是一个大型在线零售商 并且你掌握了 大量的 想要在你的网站上 实施诈骗犯罪的人 也就是说 你有很多 y=1 的样本 那么有时候 欺诈检测的方法也可能会 偏向于使用监督学习算法

还有另外一些例子 我们已经谈到了生产中的应用 我们期待看到更多的正常样本 少出现一些异常情况 但对一些生产过程来说 如果你进行大量的生产作业 并且发现了 比较多的坏的样本 那么这个问题同样也可能 转向一个监督学习问题 但如果你并没有看到 太多的不正常样本 那么还是把它当做异常检测问题来处理 

数据中心的监控机器也适用于这种情况 


相对而言 垃圾邮件分类、天气预报以及癌症诊断的问题 如果你拥有**相同数量的正负样本**或者**大量的正负样本**那么我们还是 倾向于把这些问题当做监督学习 

希望这节课能让你 明白一个学习问题的 什么样的特征 能让你把这个问题 当做是一个异常检测 或者是一个监督学习的问题 

另外对于很多技术公司 可能会遇到的一些问题 通常来说 正样本的数量很少 甚至有时候是0 也就是说出现了太多没见过的不同的异常类型 那么对于这些问题 通常应该使用的算法就是 异常检测算法

## 15.6、 Choosing What Features to Use(选择要使用的功能)

我们使用的输入异常检测算法的特征变量会对异常检测算法的应用效率产生巨大影响。

如何设计或选择异常检测算法的特征变量?

在我们的异常检测算法中使用这种正态(高斯)分布来对特征向量建模 $p(x_i;μ_i,σ_i^2)$

我们可以通过画出数据的直方图来进行模型拟合度检验，确保数据在应用异常检测算法前看起来像高斯分布  如之前的例子中，可以判断数据曲线能否很好的拟合高斯分布模型。

![15.6.1](http://m.qpic.cn/psb?/V12umJF70r2BEK/TtXbrHmCoxUBxNTrjpoTDbWWLYQUn.E6ZFxg2cNrIDM!/b/dEkBAAAAAAAA&bo=fAXxAnwF8QIDCSw!&rf=viewer_4)

如果我们的特征样本x的曲线没有很好地与模型拟合，那么我们可以尝试进行变换，来使得数据更像高斯分布，例如：

$log(x)$

$log(x+1)$  

$log(x+c)$ 

​$\sqrt x$

​$x^{1/3}$​

我们可以尝试每一种变换，然后选取出一个满意的曲线。

所有这些参数包括指数参数或者这个参数c，所有这些参数你都可以进行调整 目的只有一个：就是让数据看起来更像高斯分布 

我们来总结一下 如果你画出数据的直方图 并且发现图形看起来 非常不像正态分布 那么应该进行一些 不同的转换 就像这些 通过这些方法 来让你的数据看起来 更具有高斯分布的特点 然后你再把数据输入到学习算法

第二、如何得到异常检测算法的特征变量 

---
这是一种异常检测中的误差分析流程，和监督学习中的非常相似。

我们先完整地训练出一个学习算法 然后在一组交叉验证集上运行算法 然后找出那些预测出错的样本 然后再看看我们能否找到一些其他的特征变量来帮助学习算法 让它在那些交叉验证时判断出错的样本中表现更好 

在异常检测中，我们的目标是让正常样本的p(x)足够大，异常样本的p(x)足够小。

有一种常见的情况是，两种样本类型的p(x)一样。在这种情况下，你需要检查那些大概率给出异常样本的情况，然后尝试用新的特征量来更好地区分数据。

一般来说，选择特征量时，最好选择对于异常示例具有异常大或者小值的那些特征量。
---

我们来看一个具体点的例子 假如说这是我的无标签数据 我只有一个特征变量 x1，我要用一个高斯分布来拟合它 

假如我的数据拟合出的高斯分布是这样的 

![15.6.2](http://m.qpic.cn/psb?/V12umJF70r2BEK/a2EQeSxvYSR5naq1HlJoiFy.OMfCKaz*DeUFxGfZiNc!/b/dDIBAAAAAAAA&bo=PAXpAjwF6QIDKQw!&rf=viewer_4)

现在假如我有一个异常样本 x 的取值为2.5 画出异常样本,看起来就像被淹没在 一堆正常样本中似的 

我用绿色画出来的 这个异常样本 它是正常的的概率值很大（蓝色曲线的高度），而我们的算法没能把这个样本判断为异常 

我会看看我的训练样本 然后看看到底是 哪一个具体的数据出了异常 看看通过这个样本 能不能启发我 想出一个新的特征变量x2来帮助算法区别出不好的样本

增加新特性x2后再画出图像可能可以发现这里的绿色的样本(异常的样本)的x1特征值仍然是2.5 而x2特征值却是一个比较大的值 比如这里的3.5或者一个非常小的值 

现在如果我再来给数据建模 我会发现 我的异常检测算法 会在中间区域 给出一个较高的概率 然后越到外层越小 到了那个绿色的样本 我的异常检测算法 会给出非常小的概率值 

### Multivariate Gaussian Distribution(Optional)
---
## 15.7 Multivariate Gaussian Distribution(多变量高斯分布)

0:00
在这节和下节视频中 我想给你介绍 我们目前为止学习的异常检测算法的 一种可能的延伸 这个延伸使用了 多元高斯分布 (multivariate Gaussian distribution) 它有一些优势 也有一些劣势 它能捕捉到一些之前的算法检测不出来的异常 
0:21
为了理解这个算法 我们先来看看一个例子 
0:25
假设我们的没有标签的数据看起来像这张图一样 我要使用数据中心的监控机的例子 我要使用数据中心的监控机的例子 就是在数据中心监控计算机的例子 所以我的两个特征变量 x1 是 CPU 的负载和 x2 可能是内存使用量 
0:41
所以如果我 把这两个特征变量 x1 和 x2 当做高斯分布来建模 这个是特征变量 x1 绘制的图 这个是特征变量 x2 的图 如果我能找到一个 它所符合的高斯分布 我得到的高斯分布可能是这样的 所以这是 p(x1; 它的参数 µ1 它的参数 µ1 和 σ1 的平方 ) 然后这是内存使用量 可能我会得到这样的一个高斯分布 这是 p(x2; 参数 µ2 和 σ2 的平方 ) 因此这就是一个 异常检测算法对 x1 和 x2 建模的方法 
1:19
现在假如说 在测试集中 有一个这样的样本 
1:25
在这个绿色叉的位置 它的 x1 的值是 0.4 左右 x2 的值是 1.5 左右 现在 如果你看看 看起来它们大部分 看起来它们大部分 都在这个范围内 所以这个绿色叉 离这里看到的任何数据都很远 看起来它应该被当做 一个异常数据 所以我的 好的样本的数据 看起来 CPU 负载 和内存使用量 是彼此线性增长的关系 所以 如果我有一台机器 CPU 使用量很高 那么你就知道 内存使用量也会很高 但是这个绿色样本 看起来 CPU 负载很低 但是内存使用量很高 我以前从没在 训练集中见过这样的 看起来它应该是异常的 
2:13
但是我们来看一下异常检测算法会怎么做 对于 CPU 负载 这个绿色叉差不多在 0.5 这里 有相当高的可能性 它离看到的其它样本不远 它离看到的其它样本不远 相对的 对于内存使用量 这个点是 0.5 而对于内存使用量 它是差不多 1.5 在那里 它在这个高斯分布的尾部 它在这个高斯分布的尾部 但是这里的值和这里的值 与看到的其他那些样本 没有太大差别 所以 p(x1) 会很高 所以 p(x1) 会很高 
2:45
会比较高 p(x2) 也会比较高 我的意思是 如果你看这幅图 这里这个点 看起来它并没那么差 然后如果你看这幅图 这个叉 看起来也不那么差 我的意思是 有的样本 内存使用量更高 或者 CPU 使用量更低 所以这个点看起来不是很异常 
3:05
所以 一个异常检测算法 不会将这个点标记为异常 可以看出来 我们的异常检测算法 不能察觉到 不能察觉到 这个蓝色椭圆所表示的 好样本概率高的范围 它所做的是 这部分样本是高概率的 外面一些的圈里面的样本 
3:26
是好样本的概率低一些 而这里的样本概率更低 然后事情就变成了 那里的绿色叉 是好样本的概率挺高 
3:34
具体来说 它倾向于认为所有在这区域中的 在我画的这个圈上的样本 都具有相同的概率 它并不能意识到 这边的其实比那边的 概率要低得多 
3:55
所以 为了解决这个问题 我们要开发一种 改良版的异常检测算法 改良版的异常检测算法 要用到一种 叫做多元高斯分布或者多元正态分布的东西 
4:07
所以这是我们要做的 我们有特征 x 它是 n 维实数 我们不要把 p(x1) p(x2) 分开 而要建立一个 p(x) 整体的模型 就是一次性建立 p(x) 的模型 
4:20
多元高斯分布的参数 包括向量 µ 和一个 n×n 矩阵 Σ Σ 被称为协方差矩阵 
4:29
它类似于我们之前 在学习 PCA 也就是主成分分析的时候 也就是主成分分析的时候 所见到的协方差矩阵 
4:37
我们来试着完成这个 让我来写出 
4:40
多元高斯分布的公式 我们说 x 的概率 确定它的参数是 我的参数 µ 和 Σ 我的参数 µ 和 Σ x 的概率等于 再说一次 完全没有必要去记这个公式 
4:56
因为你可以在 任何需要用它的时候找到它 但是 x 的概率 看起来是这样的 
5:03
转置 Σ 的逆 x-µ 
5:07
这边这个东西 
5:10
Σ 的绝对值 当我们写这个符号的时候 这个东西叫做 Σ 的行列式 (determinant) 它是一个矩阵的数学函数 你不需要知道 你不需要知道 矩阵的行列式是什么 你真的需要知道的 就是可以在 Octave 里 使用 Octave 命令 det(Sigma) 来计算它 
5:33
det(Sigma) 来计算它 好 再确认一次 在这个表达式中 这些 Σ 是 n×n 矩阵 这不是一个求和符号 这个 Σ 是一个 n×n 矩阵 
5:46
所以那就是 p(x) 的公式 但是更有趣 或者说更重要的是 
5:53
p(x) 到底是什么样子 我们来看一些 多元高斯分布的例子 
6:02
我们来看一个二维的例子 我们来看一个二维的例子 如果我有 n 等于 2 两个特征 x1 和 x2 
6:09
如果说我让 µ 等于 0 如果说我让 µ 等于 0 让 Σ 等于这个矩阵 让对角线上的值等于 1 非对角线上的值等于 0 这个矩阵有时会被叫做单位矩阵 (identity matrix) 
6:21
在这个情况下 p(x) 看起来会是这样 我在这个图里展示的是 我在这个图里展示的是 对于一个特定的 x1 的值 和一个特定的 x2 的值 这个面的高度 这个面的高度 就是 p(x) 的值 所以在这个参数设定下 
6:40
p(x) 在 x1 和 x2 都等于 0 时最高 那就是高斯分布的峰值 
6:46
然后这个概率 这个二元高斯分布 随着这个二维钟形的面衰减 
6:55
下面这个图和上面是一样的 但它是用等高线 或者说不同颜色画的图 所以中间这里这个 很强烈的暗红色 对应的是最高值 然后这个值降低 黄色表示低一点儿的值 青色表示更低一些的值 这里的深蓝色 表示的是最低的值 所以这个其实是同一张图 就是采用俯视的角度 并且使用了颜色 
7:21
所以 从这个分布 
7:23
你可以看出来 大部分概率都在 0 0 附近 然后 随着从 0 0 这个点往外延伸 x1 和 x2 的概率下降 
7:36
现在我们来试试 改变一些参数 然后看看会发生什么 我们来改变一下 Σ 假如说缩小一下 Σ Σ 是一个协方差矩阵 所以它衡量的是方差 所以它衡量的是方差 或者说特征变量 x1 和 x2 的变化量 所以如果缩小 Σ 那么你的得到的是 那么你的得到的是 这个鼓包的宽度会减小 
7:57
高度会增加一点 因为在这个面以下的 区域等于 1 所以这个面以下的 体积的积分等于 1 因为概率分布的积分 必须等于一 但是 如果你缩小方差 
8:12
相当于缩小 Σ 的平方 相当于缩小 Σ 的平方 你会得到一个窄一些 高一些的分布 在这儿你也看到 这些同心椭圆也缩小了一些 而相对的 如果你 
8:29
增加 Σ 对角线上的值到 2 2 所以它现在是单位矩阵的二倍 那么最后你会得到 一个更宽更扁的高斯分布 所以这个的宽度会更宽 虽然很难看出来 但这还是一个钟形的鼓包 它只是扁平了很多 它变得更宽了 所以 x1 和 x2 的方差 或者变化量变大了 
8:50
下面再举几个例子 现在我们试一下 一次改变 Σ 的一个元素 假如说我把 Σ 改为这里是 0.6 那里是 1 
9:01
它所做事情的是 减小第一个特征变量 x1 的方差 
9:05
减小第一个特征变量 x1 的方差 同时保持第二个特征变量 x2 的方差不变 在这个参数设置下 就可以给这样的东西建模 x1 有小一些的方差 而 x2 有大一些的方差 然而如果我这样做 把这个矩阵设置为 2 1 把这个矩阵设置为 2 1 那么你也可以 建立这样的模型 
9:28
x1 的变化范围比较大 x1 的变化范围比较大 而 x2 的变化范围则窄一些 它也被反映到这张图上了 它也被反映到这张图上了 这个分布随着 x1 远离 0 这个分布随着 x1 远离 0 下降得更缓慢 而随着 x2 远离 0 下降得非常快 
9:49
类似地 如果我们改变 矩阵的这个元素 那么会类似于上一页 
9:57
除了在这儿 我们说 x2 的变化区间非常小 我们说 x2 的变化区间非常小 我们说 x2 的变化区间非常小 所以在这里 如果这个是 0.6 我们发现现在 
10:09
x2 的变化区间 比原来的例子要小很多 
10:14
然而如果我要让 Σ 等于 2 然而如果我要让 Σ 等于 2 这就是说让 x2 有大一些的变化区间 
10:22
现在 多元高斯分布的 现在 多元高斯分布的 一个很棒的事情是 你可以用它给数据的 相关性建立模型 我们可以用它 来给 x1 和 x2  高度相关的情况 建立模型 所以具体来说 如果你改变协方差矩阵 非对角线上的元素 你会得到一种不同的高斯分布 
10:46
所以当我将非对角线的元素 所以当我将非对角线的元素 从 0.5 增加到 0.8 时 我会得到一个 更加窄和高的 沿着 x=y 这条线的分布 然后这个等高线图告诉我们 x 和 y 看起来是 一起增加的 概率高的地方是这样的 概率高的地方是这样的 要么 x1 很大  x2 也很大 或者 x1 很小 x2 也很小 或者是这两者之间 然后随着这个值 0.8 增大 你会得到这样一个高斯分布 差不多全部的概率 都在一个很窄的范围内 
11:24
也就是 x 几乎等于 y 它是一个非常高 而且非常薄的分布 几乎完全在 x 非常接近于 y 的这样一个 
11:33
几乎完全在 x 非常接近于 y 的这样一个 非常窄的范围内 这是当我们把这些元素 设置为正数时的情况 相对地 如果我们 将它们设置为负数 随着我把它从 -0.5 减小到 -0.8 那么我得到的模型是 大部分的概率都在 x1 和 x2 负相关的这样一个区域内 x1 和 x2 负相关的这样一个区域内 那么大部分的概率 几乎都落在 x1 和 -x2  差不多相等的区间内 而不是 x1 等于 x2 的区间 而不是 x1 等于 x2 的区间 所以这个捕捉到了 x1 和 x2 的负相关性 
12:10
x1 和 x2 的负相关性 因此这就是一个 能让你体会到 多元高斯分布所能展现的 不同的分布 
12:18
到目前为止 我一直在改变协方差矩阵 Σ 你还可以做的事情是 改变平均值参数 µ 改变平均值参数 µ 我们的 µ 本来是等于 0 0 的 我们的 µ 本来是等于 0 0 的 所以分布才会集中在 x1=0 x2=0 这个点周围 所以这个分布的峰值在这里 所以这个分布的峰值在这里 而如果我们改变 µ 的值 它就会改变 这个分布的峰值 所以如果 µ 等于 0 0.5 这个峰值就在 x1=0 x2=0.5 这里 所以这个分布的 峰值或者说中心 就会被移动 
12:56
如果 µ 等于 1.5 -0.5 那么还是同样地 
13:01
现在分布的峰值 就会被移动到 另一个地方 这个新地方就对应 x1=1.5 x2=-0.5 这个点 所以改变参数 µ 就是在移动 这整个分布的中心 所以 希望这些 不同的图片 能够帮助你了解一下 多元高斯分布 所能描述的概率分布是什么样的 它最重要的优势 就是它可以让你 能够描述当两个特征变量之间 可能存在正相关 或者是负相关关系的情况 
13:37
在接下来的视频中 我们要把这个多元高斯分布 应用到异常检测中 【教育无边界字幕组】翻译: 竹二个 校对/审核: 所罗门捷列夫 





## 15.8、 Anomaly Detection using the Multivariate Gaussian Distribution(使用多变量高斯分布的异常检测)


在上一节视频中 我们谈到了多元高斯分布 
0:04
而且也看到了一些例子 通过改变参数 µ 和 Σ 来给不同的概率分布建模 在这节视频中 我们来使用那些想法 用它们来开发另一种异常检测算法 
0:19
再回顾一下多元高斯分布 或者叫多元正态分布 有两个参数 µ 和 Σ µ 是一个 n 维向量 协方差矩阵 Σ 
0:32
是一个 n 乘 n 矩阵 是一个 n 乘 n 矩阵 
0:37
这个式子是 x 的概率分布 这个式子是 x 的概率分布 参数是 µ 和 Σ 随着你改变 µ 和 Σ 随着你改变 µ 和 Σ 你可以得到一系列 不同的概率分布 这里有三个例子 我们在上节视频中见过 
0:51
接下来 让我们谈一下 参数拟合问题 或者说参数估计问题 和往常一样 问题是 如果我有一组样本 从 x(1) 到 x(m) 这里的每一个样本 都是 n 维向量 而且我认为它们服从多元高斯分布 
1:09
我应该怎么估计参数 µ 和 Σ 呢？ 估计它们的 标准公式是这样的 µ 等于你的 训练样本的平均值 
1:21
让 Σ 等于这个式子 这个 Σ 实际上 就是我们在使用 PCA 就是我们在使用 PCA 或者说主成分分析法时 所写的 Σ 的式子 
1:31
然后你把数据代入到 这两个式子中 就得到了估计值参数µ 和估计值参数Σ 
1:41
所以 当给定数据集时 就这样来估计 µ 和 Σ  我们来使用这个方法 把它用到 异常检测算法中 那么我怎么把这些放在一起 那么我怎么把这些放在一起 来开发一个异常检测算法呢？ 我们这样做 首先 用我们的训练集 来拟合模型 p(x) 来拟合模型 p(x) 你知道 就是要让 µ 和 Σ 等于 
2:03
上一页所描述的这样 
2:07
然后 等你拿到 一个新样本 x 如果你拿到一个测试样本 
2:12
我们还用之前的例子 拿到的新样本在这里 那是我的测试样本 
2:18
拿到一个新样本 x 我们要做的就是 用这个多元高斯分布的公式 来计算 p(x) 
2:27
然后 如果 p(x) 非常小 那我们就把它标记为一个异常点 那我们就把它标记为一个异常点 而如果 p(x) 大于那个参数 ε 那我们就不把它标记为异常点 所以说 如果我们要用一个多元高斯分布来拟合这个数据集 指的是这些红色叉 不是绿色样本 你会得到一个这样的高斯分布 大部分的概率在中间这个区域 大部分的概率在中间这个区域 这里的概率稍微低一些 这里的概率再稍微低一些 这里的概率再稍微低一些 
2:56
远处这个点的概率非常低 
3:01
所以 当你 在这个样本上用多元高斯分布 它实际上会 正确地把那个样本 标记为一个异常点 
3:16
最后 应该稍微说一下 多元高斯分布模型 多元高斯分布模型 和原来的模型 它们之间的关系 p(x) 原来的模型是 p(x1) 乘以 p(x2) 一直乘到 p(xn) 的积 p(x1) 乘以 p(x2) 一直乘到 p(xn) 的积 p(x1) 乘以 p(x2) 一直乘到 p(xn) 的积 
3:32
事实上 你可以从数学上证明 我不打算在这里进行证明 但是你可以从数学上证明 多元高斯模型 和原来的模型 之间的关系 详细来说就是 事实上原来的模型 对应于一种多元高斯分布 它的等高线 全部都是沿着轴向的 
3:55
所以这三个 全都是你可以用 原来的模型来拟合的 高斯分布的例子 事实上 它对应于 这样的多元高斯分布 这样的椭圆 这样的分布等高线 事实上这个模型 实际上它对应于一种 多元高斯分布的特例 具体来说 这个特例被定义为 
4:24
约束 p(x) 的分布 也就是多元高斯分布 p(x) 也就是多元高斯分布 p(x) 使得它的概率密度函数的等高线 使得它的概率密度函数的等高线 或者说概率分布函数的等高线 是沿着轴向的 所以你可以得到 多元高斯分布 p(x) 看起来是这样 或者是这样 或者是这样 然后你发现 在这3个例子  或者说我所画的这些椭圆中 它们的轴都是沿着 x1 x2 的轴的 
4:54
在其中没有 带有角度的 一组等高线 这个对应于那个 Σ 等于 1 1 0.8 0.8 的例子 就是非对角线上有 非零元素的例子 所以 事实上 可以用数学证明 这个模型实际上 和多元高斯分布一样 只是有一个约束 这个约束是 协方差矩阵 Σ 必须满足 非对角线的元素为0 具体来说 协方差矩阵 Σ 也就是这里这个 它等于 σ1 ^2 σ2^2 一直到 σn^2 它等于 σ1 ^2 σ2^2 一直到 σn^2 然后 所有 非对角线上的项 所有这些在矩阵对角线 
5:43
之上或者之下的元素 所有这些全都等于0 
5:47
实际上如果你 把这些 σ σ1^2 σ2^2 把这些 σ σ1^2 σ2^2 一直到 σn^2 把它们代入到这里 把它们代入到 这个协方差矩阵中 那么这两个模型实际上就完全一样了 就是说 这个新模型 
6:06
使用多元高斯分布来看 
6:08
刚好对应于这个旧模型 如果这个协方差矩阵 Σ 在非对角线上的元素 只有0的话 从图上来看 它对应于 
6:20
分布函数的等高线 是沿着轴向的高斯分布 所以你不能给不同特征变量之间的相关性建模 
6:30
这样看来 原来的模型 实际上是这个多元高斯模型的一个特例 
6:38
所以你应该在什么时候用哪个模型呢？ 什么时候该用原来的模型 什么时候该用 多元高斯模型呢？ 
6:52
原来的模型 可能使用得更加频繁 
6:58
而多元高斯模型 则没有那么常用 但是它有能够捕捉 特征变量之间的相关性的优势 
7:10
如果你想捕捉到这样的异常 如果你想捕捉到这样的异常 你有不同的特征变量 比如说特征变量 x1 x2 的值的组合是不正常的 在之前的例子中 我们的异常的例子是 CPU 负载和内存使用量的值的组合是不正常的 
7:30
如果你想用原来的模型 捕捉到这个情况 你需要建立一个新特征变量 你需要建立一个新特征变量 比如说 x3=x1/x2 可能是等于 CPU 负载除以内存使用量 或者别的什么 
7:47
你需要建立一个新特征变量 如果有不正常的变量值组合这种情况 也就是说 x1 和 x2 的取值 的组合是不正常的 虽然 x1 自己 和 x2 自己的值 
7:59
看起来非常的正常 但是如果你愿意花时间 手动建立这样的新特征变量 那么原来的模型可以很好地运行 而相对地 多元高斯模型可以自动捕捉 不同特征变量之间的相关性 但是原来的模型也有一些其他的很重要的优势 其中一个很大的优势就是 
8:28
它的运算量更小 换种说法是 它更适用于 n 的值非常大 就是说特征变量很多的情况 所以即便 n 等于 10,000 
8:39
或者 n 等于 100,000 原来的模型 通常都可以很好地运行 而对于多元高斯模型要注意 例如 我们要计算 矩阵 Σ 的逆矩阵 在这里 Σ 是一个 n 乘 n 的矩阵 
8:56
所以如果要计算的 Σ 是一个 100,000 乘 100,000 的矩阵 那么这个计算量会非常大 所以多元高斯模型 不是非常适合 n 很大的情况 最后 对于原来的模型 事实上 即使你的训练集相对较小 它也能运行得还可以 这是我们用来给 p(x) 建模的 无标签的小训练集 
9:20
当然 这个运行得很好 即使 m 可能是 
9:24
50 或者 100 也工作得很好 而对于多元高斯模型 这个算法的数学性质要求 你的 m 必须大于 n 所以样本的数量要大于特征变量的数量 我们估计参数的方法有个数学性质是 
9:41
如果不满足这个条件 就是说 m 小于或等于 n 那么这个矩阵是不可逆的 是奇异矩阵 如果你不能改变这个的话就不能使用多元高斯模型 
9:54
但是我所使用的典型的经验法则是 我只在当 m 远大于 n 的时候 使用多元高斯模型 
10:04
所以这是一个比较严格的数学要求 但是在实际中 我只有在 m 比 n 大很多的情况下 才使用多元高斯模型 所以如果 m 大于等于十倍的 n m 大于等于十倍的 n 这可能是个合理的经验法则 
10:18
如果它不满足这个 那么多元高斯模型 有很多的参数 对吧 这个协方差矩阵 Σ 是一个 n 乘 n 矩阵 所以它大概有 n 的平方个参数 因为它是个对称矩阵 实际上它有大概 n 平方除以 2 个参数 实际上它有大概 n 平方除以 2 个参数 但这是非常多的参数 所以你需要确保你的 m 比较大 确保你有足够的数据来拟合这些参数 m 大于等于十倍的 n 是一个比较合理的经验法则 它能确保你对协方差矩阵 Σ 的估计比较好 
10:55
所以在实际应用当中 左边这个原来的模型比较常用 如果你觉得 你需要捕捉特征变量之间的相关性 一般人就会手动增加这样的额外特征变量 来捕捉特定的不正常的值的组合 但是在你的训练集很大 或者说 m 很大 n 不太大的情况下 
11:17
那么多元高斯模型 是值得考虑得 或许可以运行得更好 
11:24
还可以帮你省去 为了捕捉不正常的特征值组合 才能捕捉到的异常 
11:31
而手动建立额外特征变量 所花费的时间 
11:37
最后我只想 简单提一个技术上的性质 如果你想拟合 多元高斯模型 如果你发现 协方差矩阵 Σ 是奇异的 或者说你发现 它是不可逆的 一般只有两种情况 第一种是它没有满足 这个 m 大于 n 的条件 第二种情况是 你有冗余特征变量 冗余特征变量的意思是 如果你两个一样的特征变量 不知怎么你不小心把同一个特征变量 复制了两份 那么你的 x1 刚好等于 x2 或者如果你有像这样的冗余数据 
12:12
可能是 x3=x4+x5 好了 如果你有像这样 高度冗余的特征变量 如果 x3=x4+x5 那么 x3 就不含有 任何额外的信息 对吧？ 就只是把另外两个特征变量加起来而已 
12:27
如果你有这样的 冗余特征变量 重复特征变量 或者这样的特征变量 那么 Σ 就会是不可逆的 
12:35
这是调试时候的小知识 这个应该很少发生 所以你可能不会碰到这个问题 你可能不太需要担心这个 但是万一在你实现 多元高斯模型的时候发现 Σ 是不可逆的 
12:48
我会做的首先是 确保 m 比 n 大很多 如果是这样 那么我做的第二件事是 检查冗余特征变量 如果有两个特征变量相等 就删掉其中一个 就删掉其中一个 如果你的冗余数据是 x3=x4+x5 这样的 就删掉容易的特征变量 然后它应该就可以很好地运行了 对你们之中那些 了解线性代数的人 我所说的冗余特征变量 它的正式用语是 线性相关的特征变量 但是在实际中它的意思就是 这些之中的问题导致算法有问题 如果你确保特征变量没有冗余的 应该就能解决 Σ 不可逆的问题 但是再说一次 你遇到这个问题的可能性 非常低 你可以直接应用 多元高斯模型 不需要担心 Σ 不可逆的问题 只要 m 大于等于 n 只要 m 大于等于 n 这就是应用多元高斯分布 的异常检测算法 如果你使用这个方法 你就可以使你的 异常检测算法 自动捕捉不同特征变量之间的 正相关或负相关性 并且在特征值的组合 不正常的时候 将它标记为异常 【教育无边界字幕组】翻译：竹二个 校对/审核：所罗门捷列夫 
Downloads

Lecture Videomp4
Subtitles (Chinese (Simplified))
WebVTT





### Review